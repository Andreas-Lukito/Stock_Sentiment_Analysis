{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andreas-Lukito/Stock_Sentiment_Analysis/blob/dev%2Fandreas/notebooks/03_colab_word2vec-lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "215c2c9f",
      "metadata": {
        "id": "215c2c9f"
      },
      "source": [
        "# Word2Vec + LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "ZlcArq5_0JSf"
      },
      "id": "ZlcArq5_0JSf"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install contractions emoji gensim optuna torch matplotlib"
      ],
      "metadata": {
        "id": "JmTzqyhH0NHB",
        "outputId": "d69f6d2e-4cf0-4b96-ed94-b16338f7dc80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JmTzqyhH0NHB",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.12/dist-packages (0.1.73)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (2.15.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.12/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3009e5b7",
      "metadata": {
        "id": "3009e5b7"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e85e67af",
      "metadata": {
        "id": "e85e67af",
        "outputId": "1678d09f-93f3-41f6-efcf-bb08497d48da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "seed: 3414880704\n"
          ]
        }
      ],
      "source": [
        "# Common Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Cleaner output\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Deep Learning Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import inf\n",
        "\n",
        "# Text Embedding Method\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Data Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "## Download nltk dependencies\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "## Deep Learning Hyperparameter Tuning\n",
        "import optuna\n",
        "from optuna.exceptions import TrialPruned\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "# Model metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, r2_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_path = \"/content/drive/MyDrive/stock_news_sentiment_analysis\"\n",
        "\n",
        "# Add the path to the text preprocessor\n",
        "sys.path.append(os.path.abspath(os.path.join(project_path, \"lib\")))\n",
        "\n",
        "## Import preprocessor\n",
        "from preprocessor import clean_text\n",
        "\n",
        "# Project Seed for Reproducability\n",
        "SEED = random.randint(0, 2**32 - 1)  # Random integer between 0 and 2^32-1\n",
        "print(f\"seed: {SEED}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f43bb5",
      "metadata": {
        "id": "12f43bb5"
      },
      "source": [
        "## GPU Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9627979d",
      "metadata": {
        "id": "9627979d",
        "outputId": "1e71a733-961c-4500-fa39-5b860f9333f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch is using GPU: NVIDIA A100-SXM4-80GB\n",
            "Backend: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Detect available device\n",
        "if torch.cuda.is_available():\n",
        "    # check if ROCm backend is active\n",
        "    if torch.version.hip is not None:\n",
        "        backend = \"ROCm\"\n",
        "    else:\n",
        "        backend = \"CUDA\"\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"PyTorch is using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Backend: {backend}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"PyTorch is not using GPU — running on CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19416b3a",
      "metadata": {
        "id": "19416b3a"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8ff49caa",
      "metadata": {
        "id": "8ff49caa"
      },
      "outputs": [],
      "source": [
        "before_date = \"2025-11\"\n",
        "\n",
        "# Data path\n",
        "cleaned_data_path = os.path.join(project_path,f\"news_cache/{before_date}/csv/\")\n",
        "clean_cached_file = os.path.join(cleaned_data_path, f\"{before_date}_clean_news_data.csv\")\n",
        "\n",
        "# Import Data\n",
        "news_data = pd.read_csv(filepath_or_buffer=clean_cached_file, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3e765dcf",
      "metadata": {
        "id": "3e765dcf",
        "outputId": "cbf37f06-e426-40d2-baeb-de07033396d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   uuid  \\\n",
              "0  487e6a88-d3c2-4ae1-8dc2-26af6b31d688   \n",
              "1  92b5c2bd-d324-4ae8-b115-2cfd95a8fa98   \n",
              "2  9084e5f1-75f5-4f15-aa3d-0676073b4aaf   \n",
              "3  7d36a275-f3a3-44ea-8cbc-caa0d67749c4   \n",
              "4  42ba634c-b7ce-491a-91c0-e2b1424af827   \n",
              "5  47000f09-22ab-4309-9411-c0c738327c25   \n",
              "6  927ce408-c559-4f17-b673-37b0e9e301d7   \n",
              "7  8eaf98bd-e728-4d9b-8d4b-013a8c66a173   \n",
              "8  11f67276-4330-4c68-83ad-2599ec9711b2   \n",
              "9  4800cdcb-c5b0-4055-b3c8-a71dd23d8a6e   \n",
              "\n",
              "                                               title  \\\n",
              "0                  2025: The Year Of Alphabet (GOOG)   \n",
              "1  Why I'm Doubling Down On My Adobe Position (NA...   \n",
              "2  Global week ahead: The start of a Santa Rally ...   \n",
              "3       Global Risk Monitor: Week in Review – Nov 28   \n",
              "4  Mcap boost: 7 of top-10 firms gain ₹96,201 cr;...   \n",
              "5  QQQX: Tax-Efficient Dividends From The Nasdaq-...   \n",
              "6  Wall Street predicts rebound in Indian markets...   \n",
              "7  Dow Stock: Approaching A Bottom But Recovery W...   \n",
              "8  Montrose Environmental Stock Looks Good Despit...   \n",
              "9  The Deal With Meta, Google Stock’s AI Chips To...   \n",
              "\n",
              "                                         description  \\\n",
              "0  No stock has seen a bigger jump recently than ...   \n",
              "1  Adobe's revenue is highly predictable, driven ...   \n",
              "2                                                NaN   \n",
              "3  KEY ISSUES Silver surged 13% for the week and ...   \n",
              "4  Market valuations of seven top firms rose by ₹...   \n",
              "5  Discover why Nuveen NASDAQ 100 Dynamic Overwri...   \n",
              "6  Wall Street giants anticipate a rebound for In...   \n",
              "7  Dow faces weak demand and excess capacity, but...   \n",
              "8  Discover why Montrose Environmental Group (MEG...   \n",
              "9  Discover why Alphabet is rated a Strong Buy as...   \n",
              "\n",
              "                                            keywords  \\\n",
              "0                                                NaN   \n",
              "1                                                NaN   \n",
              "2                           STOXX 600, business news   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "5                                                NaN   \n",
              "6  Indian markets rebound, Morgan Stanley India f...   \n",
              "7                                                NaN   \n",
              "8                                                NaN   \n",
              "9                                                NaN   \n",
              "\n",
              "                                             snippet  \\\n",
              "0  vzphotos/iStock Editorial via Getty Images\\n\\n...   \n",
              "1  To say that Adobe ( ADBE ) stock has not had a...   \n",
              "2  And just like that... December is upon us. It'...   \n",
              "3  KEY ISSUES\\n\\nSilver surged 13% for the week a...   \n",
              "4  The combined market valuation of seven of the ...   \n",
              "5  With the rise of covered call ETFs, it can be ...   \n",
              "6  Live Events\\n\\nBloomberg\\n\\nBloomberg\\n\\nRBI S...   \n",
              "7  Shares of Dow have been a very poor performer ...   \n",
              "8  Robert F. Abbott has been investing his family...   \n",
              "9  Alphabet Inc. ( GOOG ) ( GOOGL ) is on a fanta...   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://seekingalpha.com/article/4848680-2025-...   \n",
              "1  https://seekingalpha.com/article/4848762-why-i...   \n",
              "2  https://www.cnbc.com/2025/11/30/global-week-ah...   \n",
              "3  https://global-macro-monitor.com/2025/11/29/gl...   \n",
              "4  https://www.thehindubusinessline.com/markets/m...   \n",
              "5  https://seekingalpha.com/article/4848757-qqqx-...   \n",
              "6  https://economictimes.indiatimes.com/markets/s...   \n",
              "7  https://seekingalpha.com/article/4848756-dow-a...   \n",
              "8  https://seekingalpha.com/article/4848754-montr...   \n",
              "9  https://seekingalpha.com/article/4848753-the-d...   \n",
              "\n",
              "                                           image_url language  \\\n",
              "0  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "1  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "2  https://image.cnbcfm.com/api/v1/image/10823257...       en   \n",
              "3  https://global-macro-monitor.com/wp-content/up...       en   \n",
              "4  https://bl-i.thgim.com/public/incoming/ji6cih/...       en   \n",
              "5  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "6  https://img.etimg.com/thumb/msid-125668199,wid...       en   \n",
              "7  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "8  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "9  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "\n",
              "                  published_at                        source  relevance_score  \\\n",
              "0  2025-11-30T05:30:00.000000Z              seekingalpha.com              NaN   \n",
              "1  2025-11-30T05:25:01.000000Z              seekingalpha.com              NaN   \n",
              "2  2025-11-30T05:10:58.000000Z                      cnbc.com              NaN   \n",
              "3  2025-11-30T05:07:50.000000Z      global-macro-monitor.com              NaN   \n",
              "4  2025-11-30T05:04:20.000000Z      thehindubusinessline.com              NaN   \n",
              "5  2025-11-30T04:23:00.000000Z              seekingalpha.com              NaN   \n",
              "6  2025-11-30T04:14:43.000000Z  economictimes.indiatimes.com              NaN   \n",
              "7  2025-11-30T04:08:00.000000Z              seekingalpha.com              NaN   \n",
              "8  2025-11-30T03:38:00.000000Z              seekingalpha.com              NaN   \n",
              "9  2025-11-30T03:23:00.000000Z              seekingalpha.com              NaN   \n",
              "\n",
              "                                            entities  \\\n",
              "0  [{'symbol': 'GOOGL', 'name': 'Alphabet Inc.', ...   \n",
              "1  [{'symbol': 'ADBE', 'name': 'Adobe Inc.', 'exc...   \n",
              "2  [{'symbol': 'M', 'name': \"Macy's, Inc.\", 'exch...   \n",
              "3  [{'symbol': 'NVDA', 'name': 'NVIDIA Corporatio...   \n",
              "4  [{'symbol': 'SBKFF', 'name': 'State Bank of In...   \n",
              "5  [{'symbol': 'QQQX', 'name': 'Nuveen Nasdaq 100...   \n",
              "6  [{'symbol': 'C', 'name': 'Citigroup Inc.', 'ex...   \n",
              "7  [{'symbol': 'DOW', 'name': 'Dow Inc.', 'exchan...   \n",
              "8  [{'symbol': 'MEG', 'name': 'Montrose Environme...   \n",
              "9  [{'symbol': 'GOOG', 'name': 'Alphabet Inc.', '...   \n",
              "\n",
              "                                             similar  sentiment  \\\n",
              "0                                                 []    0.00000   \n",
              "1                                                 []    0.00000   \n",
              "2                                                 []    0.69080   \n",
              "3                                                 []   -0.36120   \n",
              "4                                                 []    0.00000   \n",
              "5                                                 []    0.37150   \n",
              "6  [{'uuid': 'd359704e-cc4f-4e18-a564-f8e189eae75...   -0.63690   \n",
              "7  [{'uuid': 'c8cdbd28-1e3c-45f5-9333-66b6b389aee...    0.00000   \n",
              "8                                                 []    0.49770   \n",
              "9                                                 []    0.61495   \n",
              "\n",
              "                                                text  length  \\\n",
              "0  vzphotos/iStock Editorial via Getty Images\\n\\n...      42   \n",
              "1  Why I'm Doubling Down On My Adobe Position (NA...       1   \n",
              "2  And just like that... December is upon us. It'...     493   \n",
              "3  KEY ISSUES\\n\\nSilver surged 13% for the week a...     729   \n",
              "4  The combined market valuation of seven of the ...     254   \n",
              "5  QQQX: Tax-Efficient Dividends From The Nasdaq-...       1   \n",
              "6  It seems like you're already an ETPrime member...      41   \n",
              "7  Dow Stock: Approaching A Bottom But Recovery W...       1   \n",
              "8  Montrose Environmental Stock Looks Good Despit...       1   \n",
              "9  The Deal With Meta, Google Stock’s AI Chips To...       1   \n",
              "\n",
              "                                          clean_text  \n",
              "0  vzphotos istock editorial via getty images sin...  \n",
              "1  doubling adobe position nasdaq adbe adobe reve...  \n",
              "2  like december upon us volatile handover novemb...  \n",
              "3  key issues silver surged 13 week 90 year date ...  \n",
              "4  combined market valuation seven top 10 valued ...  \n",
              "5  qqqx tax efficient dividends nasdaq 100 nasdaq...  \n",
              "6  seems like already etprime member login using ...  \n",
              "7  dow stock approaching bottom recovery gradual ...  \n",
              "8  montrose environmental stock looks good despit...  \n",
              "9  deal meta google stock ai chips power new cycl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-632473bf-2fbd-48c1-8f32-aa8c9c204b86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>keywords</th>\n",
              "      <th>snippet</th>\n",
              "      <th>url</th>\n",
              "      <th>image_url</th>\n",
              "      <th>language</th>\n",
              "      <th>published_at</th>\n",
              "      <th>source</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>entities</th>\n",
              "      <th>similar</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>487e6a88-d3c2-4ae1-8dc2-26af6b31d688</td>\n",
              "      <td>2025: The Year Of Alphabet (GOOG)</td>\n",
              "      <td>No stock has seen a bigger jump recently than ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vzphotos/iStock Editorial via Getty Images\\n\\n...</td>\n",
              "      <td>https://seekingalpha.com/article/4848680-2025-...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:30:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'GOOGL', 'name': 'Alphabet Inc.', ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>vzphotos/iStock Editorial via Getty Images\\n\\n...</td>\n",
              "      <td>42</td>\n",
              "      <td>vzphotos istock editorial via getty images sin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92b5c2bd-d324-4ae8-b115-2cfd95a8fa98</td>\n",
              "      <td>Why I'm Doubling Down On My Adobe Position (NA...</td>\n",
              "      <td>Adobe's revenue is highly predictable, driven ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To say that Adobe ( ADBE ) stock has not had a...</td>\n",
              "      <td>https://seekingalpha.com/article/4848762-why-i...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:25:01.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'ADBE', 'name': 'Adobe Inc.', 'exc...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Why I'm Doubling Down On My Adobe Position (NA...</td>\n",
              "      <td>1</td>\n",
              "      <td>doubling adobe position nasdaq adbe adobe reve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9084e5f1-75f5-4f15-aa3d-0676073b4aaf</td>\n",
              "      <td>Global week ahead: The start of a Santa Rally ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>STOXX 600, business news</td>\n",
              "      <td>And just like that... December is upon us. It'...</td>\n",
              "      <td>https://www.cnbc.com/2025/11/30/global-week-ah...</td>\n",
              "      <td>https://image.cnbcfm.com/api/v1/image/10823257...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:10:58.000000Z</td>\n",
              "      <td>cnbc.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'M', 'name': \"Macy's, Inc.\", 'exch...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.69080</td>\n",
              "      <td>And just like that... December is upon us. It'...</td>\n",
              "      <td>493</td>\n",
              "      <td>like december upon us volatile handover novemb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7d36a275-f3a3-44ea-8cbc-caa0d67749c4</td>\n",
              "      <td>Global Risk Monitor: Week in Review – Nov 28</td>\n",
              "      <td>KEY ISSUES Silver surged 13% for the week and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KEY ISSUES\\n\\nSilver surged 13% for the week a...</td>\n",
              "      <td>https://global-macro-monitor.com/2025/11/29/gl...</td>\n",
              "      <td>https://global-macro-monitor.com/wp-content/up...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:07:50.000000Z</td>\n",
              "      <td>global-macro-monitor.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'NVDA', 'name': 'NVIDIA Corporatio...</td>\n",
              "      <td>[]</td>\n",
              "      <td>-0.36120</td>\n",
              "      <td>KEY ISSUES\\n\\nSilver surged 13% for the week a...</td>\n",
              "      <td>729</td>\n",
              "      <td>key issues silver surged 13 week 90 year date ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42ba634c-b7ce-491a-91c0-e2b1424af827</td>\n",
              "      <td>Mcap boost: 7 of top-10 firms gain ₹96,201 cr;...</td>\n",
              "      <td>Market valuations of seven top firms rose by ₹...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The combined market valuation of seven of the ...</td>\n",
              "      <td>https://www.thehindubusinessline.com/markets/m...</td>\n",
              "      <td>https://bl-i.thgim.com/public/incoming/ji6cih/...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:04:20.000000Z</td>\n",
              "      <td>thehindubusinessline.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'SBKFF', 'name': 'State Bank of In...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>The combined market valuation of seven of the ...</td>\n",
              "      <td>254</td>\n",
              "      <td>combined market valuation seven top 10 valued ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>47000f09-22ab-4309-9411-c0c738327c25</td>\n",
              "      <td>QQQX: Tax-Efficient Dividends From The Nasdaq-...</td>\n",
              "      <td>Discover why Nuveen NASDAQ 100 Dynamic Overwri...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>With the rise of covered call ETFs, it can be ...</td>\n",
              "      <td>https://seekingalpha.com/article/4848757-qqqx-...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:23:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'QQQX', 'name': 'Nuveen Nasdaq 100...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.37150</td>\n",
              "      <td>QQQX: Tax-Efficient Dividends From The Nasdaq-...</td>\n",
              "      <td>1</td>\n",
              "      <td>qqqx tax efficient dividends nasdaq 100 nasdaq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>927ce408-c559-4f17-b673-37b0e9e301d7</td>\n",
              "      <td>Wall Street predicts rebound in Indian markets...</td>\n",
              "      <td>Wall Street giants anticipate a rebound for In...</td>\n",
              "      <td>Indian markets rebound, Morgan Stanley India f...</td>\n",
              "      <td>Live Events\\n\\nBloomberg\\n\\nBloomberg\\n\\nRBI S...</td>\n",
              "      <td>https://economictimes.indiatimes.com/markets/s...</td>\n",
              "      <td>https://img.etimg.com/thumb/msid-125668199,wid...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:14:43.000000Z</td>\n",
              "      <td>economictimes.indiatimes.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'C', 'name': 'Citigroup Inc.', 'ex...</td>\n",
              "      <td>[{'uuid': 'd359704e-cc4f-4e18-a564-f8e189eae75...</td>\n",
              "      <td>-0.63690</td>\n",
              "      <td>It seems like you're already an ETPrime member...</td>\n",
              "      <td>41</td>\n",
              "      <td>seems like already etprime member login using ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8eaf98bd-e728-4d9b-8d4b-013a8c66a173</td>\n",
              "      <td>Dow Stock: Approaching A Bottom But Recovery W...</td>\n",
              "      <td>Dow faces weak demand and excess capacity, but...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Shares of Dow have been a very poor performer ...</td>\n",
              "      <td>https://seekingalpha.com/article/4848756-dow-a...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:08:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'DOW', 'name': 'Dow Inc.', 'exchan...</td>\n",
              "      <td>[{'uuid': 'c8cdbd28-1e3c-45f5-9333-66b6b389aee...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Dow Stock: Approaching A Bottom But Recovery W...</td>\n",
              "      <td>1</td>\n",
              "      <td>dow stock approaching bottom recovery gradual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11f67276-4330-4c68-83ad-2599ec9711b2</td>\n",
              "      <td>Montrose Environmental Stock Looks Good Despit...</td>\n",
              "      <td>Discover why Montrose Environmental Group (MEG...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Robert F. Abbott has been investing his family...</td>\n",
              "      <td>https://seekingalpha.com/article/4848754-montr...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T03:38:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'MEG', 'name': 'Montrose Environme...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.49770</td>\n",
              "      <td>Montrose Environmental Stock Looks Good Despit...</td>\n",
              "      <td>1</td>\n",
              "      <td>montrose environmental stock looks good despit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4800cdcb-c5b0-4055-b3c8-a71dd23d8a6e</td>\n",
              "      <td>The Deal With Meta, Google Stock’s AI Chips To...</td>\n",
              "      <td>Discover why Alphabet is rated a Strong Buy as...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alphabet Inc. ( GOOG ) ( GOOGL ) is on a fanta...</td>\n",
              "      <td>https://seekingalpha.com/article/4848753-the-d...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T03:23:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'GOOG', 'name': 'Alphabet Inc.', '...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.61495</td>\n",
              "      <td>The Deal With Meta, Google Stock’s AI Chips To...</td>\n",
              "      <td>1</td>\n",
              "      <td>deal meta google stock ai chips power new cycl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-632473bf-2fbd-48c1-8f32-aa8c9c204b86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-632473bf-2fbd-48c1-8f32-aa8c9c204b86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-632473bf-2fbd-48c1-8f32-aa8c9c204b86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c9d1c5f5-4149-4405-91fe-6caa366c203e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9d1c5f5-4149-4405-91fe-6caa366c203e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c9d1c5f5-4149-4405-91fe-6caa366c203e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news_data",
              "summary": "{\n  \"name\": \"news_data\",\n  \"rows\": 9067,\n  \"fields\": [\n    {\n      \"column\": \"uuid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9057,\n        \"samples\": [\n          \"895f7a63-0fe8-431d-994d-b905a848bf7d\",\n          \"7458c578-eb7c-496d-b5c6-ad8cb0b9a10e\",\n          \"652e6d5a-3227-4cf6-8568-4c0e0818e497\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8881,\n        \"samples\": [\n          \"Union Pacific profits rise on operational efficiency, pricing gains\",\n          \"How Is Morgan Stanley's Stock Performance Compared to Other Capital Market Stocks\",\n          \"Intel Corporation (INTC) is Attracting Investor Attention: Here is What You Should Know\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8387,\n        \"samples\": [\n          \"Amazon's\\u00a0You buy. We donate.\\u00a0campaign is returning to help tackle hygiene poverty in the UK.\",\n          \"VANCOUVER, British Columbia, Oct. 30, 2025 (GLOBE NEWSWIRE) -- Xali Gold Corp. (TSXV:XGC) ('Xali Gold\\u201d or the 'Company\\u201d) announces that certain directors, officers, employees and consultants of the Company have been granted incentive stock options to purchase 2,200,000 common shares of Xali Gold at an exercise price equal to $0.05 per share. The options have a 5-year term, expiring October 30, 2030.\",\n          \"2025-10-28. The following slide deck was published by MSCI Inc.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3229,\n        \"samples\": [\n          \"Tidewater Inc., offshore support vessels, offshore energy industry, Tidewater, revenue guidance, marine support, marine service\",\n          \"KLN, Named, Exclusive, Distributor, for, Siemens, Healthineers\",\n          \"Larsen & Toubro, General Atomics, unmanned aircraft, MALE drones, defence ecosystem, defence manufacturing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6433,\n        \"samples\": [\n          \"Trading houses, hedge funds and banks are on a hiring spree for specialist gold traders as interest in the metal soars, creating a battle for talent that is dri...\",\n          \"Galeanu Mihai/iStock via Getty Images\\n\\nDear Partners,\\n\\nI am pleased to report that Alluvial Fund produced a return of 15.5% in the third quarter, bringing our 2...\",\n          \"Net Profit Surges 45.4% YoY in 3Q 2025\\n\\nHONG KONG, SHANGHAI, Oct. 28, 2025 /PRNewswire/ -- Ping An Insurance (Group) Company of China, Ltd. (hereafter \\\"Ping An\\\"...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9057,\n        \"samples\": [\n          \"https://www.manilatimes.net/2025/10/27/tmt-newswire/globenewswire/neumora-therapeutics-announces-initiation-of-phase-1-clinical-study-of-m4-positive-allosteric-modulator-nmra-898/2208967\",\n          \"https://finance.yahoo.com/news/ubs-lowers-airbnb-abnb-pt-133046220.html\",\n          \"https://seekingalpha.com/article/4833093-eastern-bankshares-inc-2025-q3-results-earnings-call-presentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5782,\n        \"samples\": [\n          \"https://static.seekingalpha.com/cdn/s3/uploads/getty_images/1418324628/image_1418324628.jpg?io=getty-c-w630\",\n          \"https://staticx-tuner.zacks.com/images/default_article_images/default269.jpg\",\n          \"https://argaamplus.s3.amazonaws.com/53404d14-48b9-4750-ba69-93d386c1ecc9.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"published_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8562,\n        \"samples\": [\n          \"2025-10-27T10:36:42.000000Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 180,\n        \"samples\": [\n          \"businessinsider.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9042,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similar\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1548,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30891443478745234,\n        \"min\": -0.9042,\n        \"max\": 0.9858,\n        \"num_unique_values\": 3327,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7883,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 789,\n        \"min\": 1,\n        \"max\": 12606,\n        \"num_unique_values\": 1315,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7879,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "news_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9cd4177",
      "metadata": {
        "id": "b9cd4177"
      },
      "source": [
        "## Clean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61098227",
      "metadata": {
        "id": "61098227"
      },
      "source": [
        "### Check for Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "960758c2",
      "metadata": {
        "id": "960758c2",
        "outputId": "1b9cef08-d220-4459-f958-59aa1c0c82e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Number_Missing  Missing_Percentage\n",
            "uuid                          0            0.000000\n",
            "title                         0            0.000000\n",
            "description                 414            4.566009\n",
            "keywords                   4774           52.652476\n",
            "snippet                      37            0.408073\n",
            "url                           0            0.000000\n",
            "image_url                    36            0.397044\n",
            "language                      0            0.000000\n",
            "published_at                  0            0.000000\n",
            "source                        0            0.000000\n",
            "relevance_score            9067          100.000000\n",
            "entities                      0            0.000000\n",
            "similar                       0            0.000000\n",
            "sentiment                     0            0.000000\n",
            "text                          0            0.000000\n",
            "length                        0            0.000000\n",
            "clean_text                    0            0.000000\n"
          ]
        }
      ],
      "source": [
        "is_na = pd.DataFrame(news_data.isna().sum())\n",
        "is_na.columns = [\"Number_Missing\"]\n",
        "is_na[\"Missing_Percentage\"] = (is_na[\"Number_Missing\"] / len(news_data) * 100)\n",
        "print(is_na)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f1c8b6",
      "metadata": {
        "id": "56f1c8b6"
      },
      "source": [
        "### Check for Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1402a818",
      "metadata": {
        "id": "1402a818",
        "outputId": "c8a6b267-ca2c-495f-bf40-1965ea639498",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "news_data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bff61d1",
      "metadata": {
        "id": "0bff61d1"
      },
      "source": [
        "## Split the Data to Train, Test, and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "01d36764",
      "metadata": {
        "id": "01d36764"
      },
      "outputs": [],
      "source": [
        "test_size = 0.20\n",
        "val_size = 0.10\n",
        "\n",
        "# Splitting the data into train and temp (which will be further split into validation and test)\n",
        "train_df, test_df = train_test_split(news_data, test_size=test_size, random_state=SEED)\n",
        "\n",
        "# Splitting train into validation and test sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=val_size, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff104da1",
      "metadata": {
        "id": "ff104da1"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78b88cc",
      "metadata": {
        "id": "c78b88cc"
      },
      "source": [
        "### Word Tokenization\n",
        "\n",
        "the words in the sentence would be tokenized since gensim's fasttext model requires the sentence to be tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "43969a98",
      "metadata": {
        "id": "43969a98",
        "outputId": "64282f6d-a7e2-46d1-f712-cfeaebf68094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing Train Data...: 100%|██████████| 6527/6527 [00:30<00:00, 210.96news/s]\n",
            "Preprocessing Test Data...: 100%|██████████| 1814/1814 [00:08<00:00, 219.28news/s]\n",
            "Preprocessing Validation Data...: 100%|██████████| 726/726 [00:03<00:00, 214.72news/s]\n"
          ]
        }
      ],
      "source": [
        "# tqdm for cleaner output\n",
        "tqdm.pandas(desc=\"Preprocessing Train Data...\", unit=\"news\")\n",
        "train_df[\"tokenized_text\"] = train_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Preprocessing Test Data...\", unit=\"news\")\n",
        "test_df[\"tokenized_text\"] = test_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Preprocessing Validation Data...\", unit=\"news\")\n",
        "val_df[\"tokenized_text\"] = val_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d436c5c1",
      "metadata": {
        "id": "d436c5c1"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8b1a58",
      "metadata": {
        "id": "7e8b1a58"
      },
      "source": [
        "### Train Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "554eeece",
      "metadata": {
        "id": "554eeece",
        "outputId": "095e10d6-4e3e-4ee5-92ff-f2a003d65ed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied example count (0) did not equal expected count (6527)\n",
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied raw word count (0) did not equal expected count (1574679)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied example count (0) did not equal expected count (6527)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied raw word count (0) did not equal expected count (1574679)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied example count (0) did not equal expected count (6527)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied raw word count (0) did not equal expected count (1574679)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied example count (0) did not equal expected count (6527)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied raw word count (0) did not equal expected count (1574679)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied example count (0) did not equal expected count (6527)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied raw word count (0) did not equal expected count (1574679)\n"
          ]
        }
      ],
      "source": [
        "# Train the word2vec model\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=train_df[\"tokenized_text\"].to_list(),\n",
        "    vector_size=100,\n",
        "    window=5, # Max distance from target word\n",
        "    min_count=2,\n",
        "    sg=1, # use skip gram (0 for CBOW)\n",
        "    workers=-1 #all cores to train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea353aa",
      "metadata": {
        "id": "aea353aa"
      },
      "source": [
        "### Apply Word2Vec to the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5184a23d",
      "metadata": {
        "id": "5184a23d"
      },
      "outputs": [],
      "source": [
        "# sentence vector function\n",
        "\n",
        "def get_vectors(tokens: list[str]):\n",
        "    return [w2v_model.wv.get_vector(word) for word in tokens if word in w2v_model.wv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "847b6c45",
      "metadata": {
        "id": "847b6c45",
        "outputId": "5eab5d40-2bc5-41c8-e133-63c5cae476da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Vectorizing Train Data...:   0%|          | 0/6527 [00:00<?, ?news/s]\u001b[A\n",
            "Vectorizing Train Data...:   6%|▌         | 366/6527 [00:00<00:01, 3594.02news/s]\u001b[A\n",
            "Vectorizing Train Data...:  11%|█         | 726/6527 [00:00<00:01, 3574.19news/s]\u001b[A\n",
            "Vectorizing Train Data...:  18%|█▊        | 1158/6527 [00:00<00:01, 3910.86news/s]\u001b[A\n",
            "Vectorizing Train Data...:  24%|██▍       | 1564/6527 [00:00<00:01, 3965.54news/s]\u001b[A\n",
            "Vectorizing Train Data...:  30%|███       | 1961/6527 [00:00<00:01, 3804.39news/s]\u001b[A\n",
            "Vectorizing Train Data...:  37%|███▋      | 2431/6527 [00:00<00:01, 4093.52news/s]\u001b[A\n",
            "Vectorizing Train Data...:  44%|████▎     | 2842/6527 [00:00<00:00, 3849.90news/s]\u001b[A\n",
            "Vectorizing Train Data...:  50%|████▉     | 3262/6527 [00:00<00:00, 3939.72news/s]\u001b[A\n",
            "Vectorizing Train Data...:  57%|█████▋    | 3696/6527 [00:00<00:00, 4059.56news/s]\u001b[A\n",
            "Vectorizing Train Data...:  63%|██████▎   | 4105/6527 [00:01<00:00, 3778.27news/s]\u001b[A\n",
            "Vectorizing Train Data...:  70%|███████   | 4601/6527 [00:01<00:00, 4113.27news/s]\u001b[A\n",
            "Vectorizing Train Data...:  77%|███████▋  | 5019/6527 [00:01<00:00, 4058.11news/s]\u001b[A\n",
            "Vectorizing Train Data...:  83%|████████▎ | 5429/6527 [00:01<00:00, 4035.16news/s]\u001b[A\n",
            "Vectorizing Train Data...:  89%|████████▉ | 5836/6527 [00:01<00:00, 3934.75news/s]\u001b[A\n",
            "Vectorizing Train Data...: 100%|██████████| 6527/6527 [00:01<00:00, 3845.02news/s]\n",
            "\n",
            "Vectorizing Test Data...:   0%|          | 0/1814 [00:00<?, ?news/s]\u001b[A\n",
            "Vectorizing Test Data...:  21%|██        | 376/1814 [00:00<00:00, 3751.70news/s]\u001b[A\n",
            "Vectorizing Test Data...:  45%|████▌     | 821/1814 [00:00<00:00, 4161.58news/s]\u001b[A\n",
            "Vectorizing Test Data...:  68%|██████▊   | 1238/1814 [00:00<00:00, 4035.22news/s]\u001b[A\n",
            "Vectorizing Test Data...: 100%|██████████| 1814/1814 [00:00<00:00, 4001.14news/s]\n",
            "\n",
            "Vectorizing Validation Data...:   0%|          | 0/726 [00:00<?, ?news/s]\u001b[A\n",
            "Vectorizing Validation Data...: 100%|██████████| 726/726 [00:00<00:00, 4000.92news/s]\n"
          ]
        }
      ],
      "source": [
        "# tqdm for cleaner output\n",
        "tqdm.pandas(desc=\"Vectorizing Train Data...\", unit=\"news\")\n",
        "train_df[\"vectorized_text\"] = train_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Vectorizing Test Data...\", unit=\"news\")\n",
        "test_df[\"vectorized_text\"] = test_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Vectorizing Validation Data...\", unit=\"news\")\n",
        "val_df[\"vectorized_text\"] = val_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c554397",
      "metadata": {
        "id": "1c554397"
      },
      "source": [
        "## Split the X and Y values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0e5912bc",
      "metadata": {
        "id": "0e5912bc"
      },
      "outputs": [],
      "source": [
        "x_train = train_df[\"vectorized_text\"]\n",
        "x_test = test_df[\"vectorized_text\"]\n",
        "x_val = val_df[\"vectorized_text\"]\n",
        "\n",
        "y_train = train_df[\"sentiment\"].to_numpy()\n",
        "y_test = test_df[\"sentiment\"].to_numpy()\n",
        "y_val = val_df[\"sentiment\"].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ac814e",
      "metadata": {
        "id": "62ac814e"
      },
      "source": [
        "## Apply Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5d1f92b6",
      "metadata": {
        "id": "5d1f92b6"
      },
      "outputs": [],
      "source": [
        "# Padding Function\n",
        "def pad_sequences(vectorized_sentences, max_len=300):\n",
        "    padded_list = []\n",
        "\n",
        "    for vec in vectorized_sentences:\n",
        "        vec = torch.tensor(vec, dtype=torch.float32)\n",
        "\n",
        "        # Truncate if too long\n",
        "        if vec.shape[0] > max_len:\n",
        "            vec = vec[:max_len]\n",
        "\n",
        "        # Pad if too short\n",
        "        if vec.shape[0] < max_len:\n",
        "            pad_length = max_len - vec.shape[0]\n",
        "            padding = torch.zeros((pad_length, vec.shape[1]))  # (pad_len, embedding_dim)\n",
        "            vec = torch.cat([vec, padding], dim=0)  # post-padding\n",
        "\n",
        "        padded_list.append(vec)\n",
        "\n",
        "    return torch.stack(padded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b9db4712",
      "metadata": {
        "id": "b9db4712"
      },
      "outputs": [],
      "source": [
        "max_padding_len = 300\n",
        "\n",
        "x_train_vectors = x_train.tolist()\n",
        "x_train_padded = pad_sequences(x_train_vectors, max_len = max_padding_len)\n",
        "x_train_padded = x_train_padded.numpy()\n",
        "\n",
        "x_test_vectors = x_test.tolist()\n",
        "x_test_padded = pad_sequences(x_test_vectors, max_len = max_padding_len)\n",
        "x_test_padded = x_test_padded.numpy()\n",
        "\n",
        "x_val_vectors = x_val.tolist()\n",
        "x_val_padded = pad_sequences(x_val_vectors, max_len = max_padding_len)\n",
        "x_val_padded = x_val_padded.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca3a5a3",
      "metadata": {
        "id": "eca3a5a3"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Train data\n",
        "x_train_tensor = torch.tensor(x_train_padded, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# test data\n",
        "x_test_tensor = torch.tensor(x_test_padded, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# val data\n",
        "x_val_tensor = torch.tensor(x_val_padded, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "aslIlBYz2gby"
      },
      "id": "aslIlBYz2gby",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "79b5828b",
      "metadata": {
        "id": "79b5828b"
      },
      "source": [
        "## Build LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0107a86",
      "metadata": {
        "id": "c0107a86"
      },
      "source": [
        "### Model Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a98097dc",
      "metadata": {
        "id": "a98097dc"
      },
      "outputs": [],
      "source": [
        "def define_model(trial, input_size, n_output):\n",
        "    class GridLSTM(nn.Module):\n",
        "        def __init__(self, trial, input_size: int, hidden_size: int, num_layers: int, n_output: int):\n",
        "            super().__init__()\n",
        "\n",
        "            def dense_layer_builder(layer_prefix):\n",
        "                nonlocal input_size, dense_layers\n",
        "\n",
        "                # Dense layer parameters\n",
        "                out_size = trial.suggest_int(f\"{layer_prefix}_output_size\", 32, 512)\n",
        "                dense_layers.append(nn.Linear(input_size, out_size))\n",
        "\n",
        "                # Add drop out rate so that it reduces overfitting and improve generlization\n",
        "                dropout_rate = trial.suggest_float(f\"{layer_prefix}_dropout_rate\", 0.0, 0.8)\n",
        "                if dropout_rate > 0:\n",
        "                    dense_layers.append(nn.Dropout(dropout_rate)) # Update input size for the next dense layer based on the output size of this one\n",
        "\n",
        "                input_size = out_size\n",
        "\n",
        "            if num_layers >= 3:\n",
        "                lstm_dropout = trial.suggest_float(\"lstm_dropout\", 0.0, 0.8)\n",
        "            else:\n",
        "                lstm_dropout = 0\n",
        "                trial.set_user_attr(\"lstm_dropout\", lstm_dropout)\n",
        "\n",
        "            self.hidden_size = hidden_size\n",
        "            self.num_layers = num_layers\n",
        "\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size = input_size,\n",
        "                hidden_size = hidden_size, #number of LSTM Blocks\n",
        "                num_layers = num_layers, #number of LSTM layers\n",
        "                batch_first = True, # so that pytorch recognizes the input to be [batch_size, sequence_length, input_size] otherwise [sequence_length, batch_size, input_size]\n",
        "                dropout = lstm_dropout\n",
        "            )\n",
        "\n",
        "            # Make the dense layers\n",
        "            dense_layers = []\n",
        "            input_size = hidden_size\n",
        "            n_dense_layers = trial.suggest_int(\"n_dense_layer\", 1, 25)\n",
        "\n",
        "            for i in range(n_dense_layers):\n",
        "                dense_layer_builder(f\"dense_{i}\") #input size would be updated each iteration\n",
        "\n",
        "            #output Layer\n",
        "            dense_layers.append(nn.Linear(input_size, n_output))\n",
        "\n",
        "            # Register dense layers as nn.Sequential\n",
        "            self.dense = nn.Sequential(*dense_layers)\n",
        "\n",
        "        def forward(self, input_tensor): # Forward pass\n",
        "            if input_tensor.dim() == 2:  # [seq_len, input_size] unbatched\n",
        "                input_tensor = input_tensor.unsqueeze(1)  # make [1, seq_len, input_size] if the dimensions\n",
        "                batch_size = input_tensor.size(0)\n",
        "                h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "                c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            else:  # [batch_size, seq_len, input_size]\n",
        "                batch_size = input_tensor.size(0)\n",
        "                h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "                c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            out, _ = self.lstm(input_tensor, (h0, c0))  # LSTM forward\n",
        "            out = self.dense(out[:, -1, :])             # Take last time step and pass through dense\n",
        "            return out\n",
        "\n",
        "    hidden_size = trial.suggest_int(\"lstm_hidden_size\", 8, 512)\n",
        "    num_layers = trial.suggest_int(\"lstm_num_layers\", 1, 6)\n",
        "    return GridLSTM(trial, input_size, hidden_size, num_layers, n_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da715301",
      "metadata": {
        "id": "da715301"
      },
      "source": [
        "### Optuna Objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "69054d08",
      "metadata": {
        "id": "69054d08"
      },
      "outputs": [],
      "source": [
        "def objective(trial, n_input, n_output, train_loader, val_loader, epochs, device):\n",
        "    # Reset the seed for each trial of the gridsearch\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    # Parameters for early stopping\n",
        "    best_mse = inf # Inital MSE score\n",
        "    patience = 3 # number of epochs to wait without improvement before stopping\n",
        "    epochs_no_improve = 0 # Epochs counter without improvement\n",
        "    best_model_state = None # To store the best model weights\n",
        "\n",
        "    # Model Initialization\n",
        "    model = define_model(trial, n_input, n_output).to(device)\n",
        "\n",
        "    # Learning rate\n",
        "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)  # log-scale search\n",
        "\n",
        "    # Optimizer Set-Up\n",
        "    optimizer_name = trial.suggest_categorical(\"Optimizer\", [\"Adam\", \"Momentum\", \"AdamW\"])\n",
        "    optimizer = {\n",
        "        \"Adam\": optim.Adam(model.parameters(), lr=lr),\n",
        "        \"Momentum\": optim.SGD(model.parameters(),\n",
        "                            lr=lr,\n",
        "                            momentum=trial.suggest_float(\"sgd_momentum\", 1e-5, 1, log=True)),\n",
        "        \"AdamW\": optim.AdamW(model.parameters(),\n",
        "                            lr=lr,\n",
        "                            weight_decay=trial.suggest_float(\"adamw_weight_decay\", 1e-5, 1, log=True))\n",
        "    }[optimizer_name]\n",
        "\n",
        "    # Loss function\n",
        "    loss_function = nn.MSELoss() # This is to punish the model for large errors\n",
        "\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training model...\"):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        for inputs, true_values in train_loader:\n",
        "            inputs, true_values = inputs.to(device), true_values.to(device) # Set the device to train on\n",
        "\n",
        "            optimizer.zero_grad() # Resets all the gradients since pytorch accumulates gradients from previous training\n",
        "            outputs = model(inputs) # Runs a forward pass\n",
        "            loss = loss_function(outputs.view(-1), true_values.view(-1)) # Calculates the error\n",
        "            loss.backward() # Runs a Backward pass\n",
        "            optimizer.step() # Updates model trainable parameters\n",
        "\n",
        "        # Early Stopping Check\n",
        "        # Validation (after training loop finishes)\n",
        "        model.eval() # Make model in evaluation mode\n",
        "        all_preds = [] # For the model predictions and true lables\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad(): # Turns off gradient tracking for speeding up validation, saves memory, lock memory weights\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device).float(), labels.to(device).float() # move lables to the device\n",
        "                outputs = model(inputs) # Pass input data to the model to get raw logits\n",
        "\n",
        "                all_preds.extend(outputs.squeeze().cpu().numpy()) # move the predictions and lables to the cpu since numpy only works on CPU memory. then convert to numpy arrays then append to the list.\n",
        "                all_labels.extend(labels.squeeze().cpu().numpy())\n",
        "\n",
        "        # Calculate MSE Score\n",
        "        curr_mse = mean_squared_error(all_labels, all_preds) # Calculate mse score\n",
        "\n",
        "        if curr_mse < best_mse:\n",
        "            best_mse = curr_mse\n",
        "            epochs_no_improve = 0\n",
        "            best_model_state = deepcopy(model.state_dict()) # Save the model state\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                tqdm.write(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    # Load best model weights for reporting\n",
        "    model.load_state_dict(best_model_state)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad(): # Turns off gradient tracking for speeding up validation, saves memory, lock memory weights\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move lables to the device\n",
        "            outputs = model(inputs) # Pass input data to the model to get raw logits\n",
        "\n",
        "            all_preds.extend(outputs.squeeze().cpu().numpy()) # move the predictions and lables to the cpu since numpy only works on CPU memory. then convert to numpy arrays then append to the list.\n",
        "            all_labels.extend(labels.squeeze().cpu().numpy())\n",
        "\n",
        "    best_mse = mean_squared_error(all_labels, all_preds)\n",
        "    tqdm.write(f\"Trial {trial.number}: Best MSE Score = {best_mse:.4f}\")\n",
        "    trial.set_user_attr(\"best_model_state\", best_model_state)\n",
        "    return best_mse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eae52f0",
      "metadata": {
        "id": "2eae52f0"
      },
      "source": [
        "### Initiate Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "98b999b0",
      "metadata": {
        "id": "98b999b0",
        "outputId": "fab39c3d-36ff-4b5e-986e-9e847770a9a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training model...:   0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Training model...:   3%|▎         | 1/30 [00:06<03:13,  6.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "Training model...:   7%|▋         | 2/30 [00:13<03:05,  6.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "Training model...:  10%|█         | 3/30 [00:19<02:59,  6.65s/it]\u001b[A\u001b[A\n",
            "\n",
            "Training model...:  13%|█▎        | 4/30 [00:26<02:52,  6.62s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\n",
            "\n",
            "Gridsearch ...:  97%|█████████▋| 29/30 [39:33<00:51, 51.66s/it]\n",
            "Training model...:  13%|█▎        | 4/30 [00:33<03:35,  8.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Gridsearch ...:  97%|█████████▋| 29/30 [39:33<00:51, 51.66s/it]\n",
            "Trial:   0%|                                             | 0/30 [39:33<?, ?it/s]\u001b[A[I 2025-12-15 03:12:07,344] Trial 29 finished with value: 0.09905831841625709 and parameters: {'lstm_hidden_size': 404, 'lstm_num_layers': 3, 'lstm_dropout': 0.017157617999028013, 'n_dense_layer': 12, 'dense_0_output_size': 188, 'dense_0_dropout_rate': 0.33158295266549376, 'dense_1_output_size': 465, 'dense_1_dropout_rate': 0.7154915258982835, 'dense_2_output_size': 37, 'dense_2_dropout_rate': 0.6028367866741974, 'dense_3_output_size': 80, 'dense_3_dropout_rate': 0.46321380570347304, 'dense_4_output_size': 357, 'dense_4_dropout_rate': 0.4047784544779359, 'dense_5_output_size': 357, 'dense_5_dropout_rate': 0.667722978582387, 'dense_6_output_size': 509, 'dense_6_dropout_rate': 0.7922103034865597, 'dense_7_output_size': 448, 'dense_7_dropout_rate': 0.014317706759419069, 'dense_8_output_size': 58, 'dense_8_dropout_rate': 0.282258042290119, 'dense_9_output_size': 506, 'dense_9_dropout_rate': 0.003870534243741952, 'dense_10_output_size': 485, 'dense_10_dropout_rate': 0.5583316368687978, 'dense_11_output_size': 325, 'dense_11_dropout_rate': 0.2589843312483194, 'learning_rate': 0.003562234056158708, 'Optimizer': 'Adam', 'sgd_momentum': 0.0004704802803397102, 'adamw_weight_decay': 0.0009854726821682848}. Best is trial 12 with value: 0.09903110201838597.\n",
            "Gridsearch ...: 100%|██████████| 30/30 [39:33<00:00, 79.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 29: Best MSE Score = 0.0991\n",
            "\n",
            "study statistics:\n",
            "  Finished trials: 30\n",
            "  Pruned trials:   0\n",
            "  Complete trials: 30\n",
            "Best trial:\n",
            "  Best MSE: 0.0990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# The input size\n",
        "input_size = x_train_padded.shape[2]\n",
        "\n",
        "# Get number of outputs\n",
        "output_size = 1 # since this is regression there would be only 1 output\n",
        "epochs = 30\n",
        "n_trials = 30\n",
        "\n",
        "samplers = optuna.samplers.TPESampler(n_startup_trials=20) # Bayesian optimization method used by Optuna to sample hyperparameters intelligently (20 random trials first before starting the Bayesian optimization.)\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=samplers) # Minimize MSE score\n",
        "\n",
        "# Tqdm for cleaner output\n",
        "progress_bar = tqdm(total=n_trials, desc=\"Trial\", ncols=80)\n",
        "\n",
        "for _ in tqdm(range(n_trials), desc=\"Gridsearch ...\"):\n",
        "    time.sleep(0.8) #wait for .8 seconds befor clearing the output\n",
        "    clear_output(wait=True) # comment this out of you want to see the whole training process\n",
        "    study.optimize(lambda trial: objective(trial,input_size, output_size, train_loader,\n",
        "                                            val_loader, epochs, device),\n",
        "                    n_trials=1)\n",
        "\n",
        "# Summarize study results\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED]) # get the pruned trials\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE]) # get the succeeded trials\n",
        "\n",
        "print(\"\\nstudy statistics:\")\n",
        "print(f\"  Finished trials: {len(study.trials)}\")\n",
        "print(f\"  Pruned trials:   {len(pruned_trials)}\")\n",
        "print(f\"  Complete trials: {len(complete_trials)}\")\n",
        "\n",
        "# Define model with best params\n",
        "best_trial = study.best_trial\n",
        "print(\"Best trial:\")\n",
        "print(f\"  Best MSE: {best_trial.value:.4f}\")\n",
        "best_model = define_model(best_trial, input_size, output_size).to(device)\n",
        "\n",
        "# Load best weights\n",
        "best_model.load_state_dict(best_trial.user_attrs[\"best_model_state\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75e65b7",
      "metadata": {
        "id": "d75e65b7"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "874e9ce5",
      "metadata": {
        "id": "874e9ce5"
      },
      "source": [
        "### Model Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0e52b5aa",
      "metadata": {
        "id": "0e52b5aa"
      },
      "outputs": [],
      "source": [
        "# Model Builder from Parameters\n",
        "def define_model_from_params(params: dict, input_size: int, n_output: int):\n",
        "    class GridLSTM(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            self.hidden_size = params[\"lstm_hidden_size\"]\n",
        "            self.num_layers = params[\"lstm_num_layers\"]\n",
        "            self.lstm_dropout = params.get(\"lstm_dropout\", 0.0)\n",
        "\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                batch_first=True,\n",
        "                dropout=self.lstm_dropout\n",
        "            )\n",
        "            # Build dense layers\n",
        "            dense_layers = []\n",
        "            dense_input_size = self.lstm.hidden_size\n",
        "            n_dense_layers = params.get(\"n_dense_layer\", 1)\n",
        "\n",
        "            for i in range(n_dense_layers):\n",
        "                out_size = params[f\"dense_{i}_output_size\"]\n",
        "                dense_layers.append(nn.Linear(dense_input_size, out_size))\n",
        "\n",
        "                dropout_rate = params.get(f\"dense_{i}_dropout_rate\", 0.0)\n",
        "                if dropout_rate > 0:\n",
        "                    dense_layers.append(nn.Dropout(dropout_rate))\n",
        "\n",
        "                dense_input_size = out_size\n",
        "\n",
        "            # Output layer\n",
        "            dense_layers.append(nn.Linear(dense_input_size, n_output))\n",
        "            self.dense = nn.Sequential(*dense_layers)\n",
        "\n",
        "        def forward(self, input_tensor):\n",
        "            if input_tensor.dim() == 2:  # [batch_size, input_size]\n",
        "                input_tensor = input_tensor.unsqueeze(1)  # make it [batch_size, seq_len=1, input_size]\n",
        "\n",
        "            batch_size = input_tensor.size(0)\n",
        "\n",
        "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            # LSTM Forward pass\n",
        "            out, _ = self.lstm(input_tensor, (h0, c0)) # out: [batch_size, seq_len, hidden_size]\n",
        "            out = self.dense(out[:, -1, :]) # take the last time step and pass it to the dense layer\n",
        "            return out\n",
        "\n",
        "    return GridLSTM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "273c6bf7",
      "metadata": {
        "id": "273c6bf7"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            all_preds.extend(outputs.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "    # Compute metrics\n",
        "    mse = mean_squared_error(all_labels, all_preds)\n",
        "    mae = mean_absolute_error(all_labels, all_preds)\n",
        "    rmse = root_mean_squared_error(all_labels, all_preds)\n",
        "    r2 = r2_score(all_labels, all_preds)\n",
        "\n",
        "    return mse, mae, rmse, r2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9ac2820",
      "metadata": {
        "id": "e9ac2820"
      },
      "source": [
        "### Export and Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "e289f630",
      "metadata": {
        "id": "e289f630",
        "outputId": "f98016d9-780d-4a28-b79c-31e9f571fe6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Score:\n",
            "New_mse       = 0.0932\n",
            "New_mae       = 0.2539\n",
            "New_rmse      = 0.3054\n",
            "new_r²        = -0.0043\n",
            "\n",
            "\n",
            "📥 No existing model — saving new model.\n"
          ]
        }
      ],
      "source": [
        "model_pytorch_path = os.path.join(project_path,\"models/word2vec_lstm/word2vec_lstm_model.pt\")\n",
        "model_json_path = os.path.join(project_path,\"models/word2vec_lstm/word2vec_lstm_model.json\")\n",
        "seed_path = os.path.join(project_path,\"models/word2vec_lstm/seed.txt\")\n",
        "new_model = best_model.to(device)\n",
        "new_model.eval()\n",
        "\n",
        "# Evaluate new model on test set\n",
        "new_mse, new_mae, new_rmse, new_r2 = evaluate_model(\n",
        "                                    new_model,\n",
        "                                    test_loader,\n",
        "                                    device\n",
        "                                    )\n",
        "\n",
        "if os.path.exists(model_pytorch_path) and os.path.exists(model_json_path):\n",
        "    # Load the existing (old) model\n",
        "    with open(model_json_path, \"r\") as f:\n",
        "        best_old_params = json.load(f)\n",
        "\n",
        "    old_model = define_model_from_params(best_old_params, input_size, output_size).to(device)\n",
        "    old_model.load_state_dict(torch.load(model_pytorch_path))\n",
        "    old_model.eval()\n",
        "\n",
        "    # Evaluate the old model\n",
        "    old_mse, old_mae, old_rmse, old_r2 = evaluate_model(\n",
        "                                        old_model,\n",
        "                                        test_loader,\n",
        "                                        device\n",
        "                                        )\n",
        "    print(\"Model Scores:\")\n",
        "    print(f\"Old_mse       = {old_mse:.4f}     | New_mse       = {new_mse:.4f}\")\n",
        "    print(f\"Old_mae       = {old_mae:.4f}     | New_mae       = {new_mae:.4f}\")\n",
        "    print(f\"Old_rmse      = {old_rmse:.4f}    | New_rmse      = {new_rmse:.4f}\")\n",
        "    print(f\"Old_r²        = {old_r2:.4f}      | new_r²        = {new_r2:.4f}\")\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    if new_mse < old_mse:\n",
        "        print(\"🔁 New model is better — overwriting saved model.\")\n",
        "        torch.save(new_model.state_dict(), model_pytorch_path)\n",
        "\n",
        "        with open(model_json_path, \"w\") as f:\n",
        "            json.dump(best_trial.params, f, indent=4)\n",
        "\n",
        "        with open(seed_path, \"w\") as file:\n",
        "            file.write(str(SEED))\n",
        "\n",
        "        model = new_model\n",
        "    else:\n",
        "        print(\"✅ Existing model is still better.\")\n",
        "        model = old_model\n",
        "else:\n",
        "    print(\"Model Score:\")\n",
        "    print(f\"New_mse       = {new_mse:.4f}\")\n",
        "    print(f\"New_mae       = {new_mae:.4f}\")\n",
        "    print(f\"New_rmse      = {new_rmse:.4f}\")\n",
        "    print(f\"new_r²        = {new_r2:.4f}\")\n",
        "    print()\n",
        "    print()\n",
        "    print(\"📥 No existing model — saving new model.\")\n",
        "    os.makedirs(os.path.join(project_path, \"models/word2vec_lstm/\"), exist_ok=True)\n",
        "    torch.save(new_model.state_dict(), model_pytorch_path)\n",
        "    with open(model_json_path, \"w\") as f:\n",
        "        json.dump(best_trial.params, f, indent=4)\n",
        "    with open(seed_path, \"w\") as file:\n",
        "        file.write(str(SEED))\n",
        "    model = new_model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}