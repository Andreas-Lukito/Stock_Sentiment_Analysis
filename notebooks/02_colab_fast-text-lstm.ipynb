{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andreas-Lukito/Stock_Sentiment_Analysis/blob/dev%2Fandreas/notebooks/02_colab_fast-text-lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "215c2c9f",
      "metadata": {
        "id": "215c2c9f"
      },
      "source": [
        "# Fast Text + LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a0242b8",
      "metadata": {
        "id": "0a0242b8"
      },
      "source": [
        "## Instal Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "01650d9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01650d9d",
        "outputId": "38ba126c-de44-4732-c2fa-8de64b0e9963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.12/dist-packages (0.1.73)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (2.15.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.12/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install contractions emoji gensim optuna torch matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3009e5b7",
      "metadata": {
        "id": "3009e5b7"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e85e67af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e85e67af",
        "outputId": "805b05f3-5a6a-4a05-aa74-25a9757e2c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "seed: 219913815\n"
          ]
        }
      ],
      "source": [
        "# Common Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Cleaner output\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Deep Learning Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import inf\n",
        "\n",
        "# Text Embedding Method\n",
        "from gensim.models import FastText\n",
        "\n",
        "# Data Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "## Download nltk dependencies\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Deep Learning Hyperparameter Tuning\n",
        "import optuna\n",
        "from optuna.exceptions import TrialPruned\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "# Model metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_path = \"/content/drive/MyDrive/stock_news_sentiment_analysis\"\n",
        "\n",
        "# Add the path to the text preprocessor\n",
        "sys.path.append(os.path.abspath(os.path.join(project_path, \"lib\")))\n",
        "\n",
        "## Import preprocessor\n",
        "from preprocessor import clean_text\n",
        "\n",
        "# Project Seed for Reproducability\n",
        "SEED = random.randint(0, 2**32 - 1)  # Random integer between 0 and 2^32-1\n",
        "print(f\"seed: {SEED}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f43bb5",
      "metadata": {
        "id": "12f43bb5"
      },
      "source": [
        "## GPU Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9627979d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9627979d",
        "outputId": "eb9c6da6-ef55-4f76-a127-db5b5243167b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch is using GPU: NVIDIA A100-SXM4-80GB\n",
            "Backend: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Detect available device\n",
        "if torch.cuda.is_available():\n",
        "    # check if ROCm backend is active\n",
        "    if torch.version.hip is not None:\n",
        "        backend = \"ROCm\"\n",
        "    else:\n",
        "        backend = \"CUDA\"\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"PyTorch is using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Backend: {backend}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"PyTorch is not using GPU — running on CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19416b3a",
      "metadata": {
        "id": "19416b3a"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8ff49caa",
      "metadata": {
        "id": "8ff49caa"
      },
      "outputs": [],
      "source": [
        "before_date = \"2025-11\"\n",
        "\n",
        "# Data path\n",
        "cleaned_data_path = os.path.join(project_path,f\"news_cache/{before_date}/csv/\")\n",
        "clean_cached_file = os.path.join(cleaned_data_path, f\"{before_date}_clean_news_data.csv\")\n",
        "\n",
        "# Import Data\n",
        "news_data = pd.read_csv(filepath_or_buffer=clean_cached_file, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3e765dcf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3e765dcf",
        "outputId": "1a8a134a-b605-453d-b602-2f781d4bc99e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   uuid  \\\n",
              "0  487e6a88-d3c2-4ae1-8dc2-26af6b31d688   \n",
              "1  92b5c2bd-d324-4ae8-b115-2cfd95a8fa98   \n",
              "2  9084e5f1-75f5-4f15-aa3d-0676073b4aaf   \n",
              "3  7d36a275-f3a3-44ea-8cbc-caa0d67749c4   \n",
              "4  42ba634c-b7ce-491a-91c0-e2b1424af827   \n",
              "5  47000f09-22ab-4309-9411-c0c738327c25   \n",
              "6  927ce408-c559-4f17-b673-37b0e9e301d7   \n",
              "7  8eaf98bd-e728-4d9b-8d4b-013a8c66a173   \n",
              "8  11f67276-4330-4c68-83ad-2599ec9711b2   \n",
              "9  4800cdcb-c5b0-4055-b3c8-a71dd23d8a6e   \n",
              "\n",
              "                                               title  \\\n",
              "0                  2025: The Year Of Alphabet (GOOG)   \n",
              "1  Why I'm Doubling Down On My Adobe Position (NA...   \n",
              "2  Global week ahead: The start of a Santa Rally ...   \n",
              "3       Global Risk Monitor: Week in Review – Nov 28   \n",
              "4  Mcap boost: 7 of top-10 firms gain ₹96,201 cr;...   \n",
              "5  QQQX: Tax-Efficient Dividends From The Nasdaq-...   \n",
              "6  Wall Street predicts rebound in Indian markets...   \n",
              "7  Dow Stock: Approaching A Bottom But Recovery W...   \n",
              "8  Montrose Environmental Stock Looks Good Despit...   \n",
              "9  The Deal With Meta, Google Stock’s AI Chips To...   \n",
              "\n",
              "                                         description  \\\n",
              "0  No stock has seen a bigger jump recently than ...   \n",
              "1  Adobe's revenue is highly predictable, driven ...   \n",
              "2                                                NaN   \n",
              "3  KEY ISSUES Silver surged 13% for the week and ...   \n",
              "4  Market valuations of seven top firms rose by ₹...   \n",
              "5  Discover why Nuveen NASDAQ 100 Dynamic Overwri...   \n",
              "6  Wall Street giants anticipate a rebound for In...   \n",
              "7  Dow faces weak demand and excess capacity, but...   \n",
              "8  Discover why Montrose Environmental Group (MEG...   \n",
              "9  Discover why Alphabet is rated a Strong Buy as...   \n",
              "\n",
              "                                            keywords  \\\n",
              "0                                                NaN   \n",
              "1                                                NaN   \n",
              "2                           STOXX 600, business news   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "5                                                NaN   \n",
              "6  Indian markets rebound, Morgan Stanley India f...   \n",
              "7                                                NaN   \n",
              "8                                                NaN   \n",
              "9                                                NaN   \n",
              "\n",
              "                                             snippet  \\\n",
              "0  vzphotos/iStock Editorial via Getty Images\\n\\n...   \n",
              "1  To say that Adobe ( ADBE ) stock has not had a...   \n",
              "2  And just like that... December is upon us. It'...   \n",
              "3  KEY ISSUES\\n\\nSilver surged 13% for the week a...   \n",
              "4  The combined market valuation of seven of the ...   \n",
              "5  With the rise of covered call ETFs, it can be ...   \n",
              "6  Live Events\\n\\nBloomberg\\n\\nBloomberg\\n\\nRBI S...   \n",
              "7  Shares of Dow have been a very poor performer ...   \n",
              "8  Robert F. Abbott has been investing his family...   \n",
              "9  Alphabet Inc. ( GOOG ) ( GOOGL ) is on a fanta...   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://seekingalpha.com/article/4848680-2025-...   \n",
              "1  https://seekingalpha.com/article/4848762-why-i...   \n",
              "2  https://www.cnbc.com/2025/11/30/global-week-ah...   \n",
              "3  https://global-macro-monitor.com/2025/11/29/gl...   \n",
              "4  https://www.thehindubusinessline.com/markets/m...   \n",
              "5  https://seekingalpha.com/article/4848757-qqqx-...   \n",
              "6  https://economictimes.indiatimes.com/markets/s...   \n",
              "7  https://seekingalpha.com/article/4848756-dow-a...   \n",
              "8  https://seekingalpha.com/article/4848754-montr...   \n",
              "9  https://seekingalpha.com/article/4848753-the-d...   \n",
              "\n",
              "                                           image_url language  \\\n",
              "0  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "1  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "2  https://image.cnbcfm.com/api/v1/image/10823257...       en   \n",
              "3  https://global-macro-monitor.com/wp-content/up...       en   \n",
              "4  https://bl-i.thgim.com/public/incoming/ji6cih/...       en   \n",
              "5  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "6  https://img.etimg.com/thumb/msid-125668199,wid...       en   \n",
              "7  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "8  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "9  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "\n",
              "                  published_at                        source  relevance_score  \\\n",
              "0  2025-11-30T05:30:00.000000Z              seekingalpha.com              NaN   \n",
              "1  2025-11-30T05:25:01.000000Z              seekingalpha.com              NaN   \n",
              "2  2025-11-30T05:10:58.000000Z                      cnbc.com              NaN   \n",
              "3  2025-11-30T05:07:50.000000Z      global-macro-monitor.com              NaN   \n",
              "4  2025-11-30T05:04:20.000000Z      thehindubusinessline.com              NaN   \n",
              "5  2025-11-30T04:23:00.000000Z              seekingalpha.com              NaN   \n",
              "6  2025-11-30T04:14:43.000000Z  economictimes.indiatimes.com              NaN   \n",
              "7  2025-11-30T04:08:00.000000Z              seekingalpha.com              NaN   \n",
              "8  2025-11-30T03:38:00.000000Z              seekingalpha.com              NaN   \n",
              "9  2025-11-30T03:23:00.000000Z              seekingalpha.com              NaN   \n",
              "\n",
              "                                            entities  \\\n",
              "0  [{'symbol': 'GOOGL', 'name': 'Alphabet Inc.', ...   \n",
              "1  [{'symbol': 'ADBE', 'name': 'Adobe Inc.', 'exc...   \n",
              "2  [{'symbol': 'M', 'name': \"Macy's, Inc.\", 'exch...   \n",
              "3  [{'symbol': 'NVDA', 'name': 'NVIDIA Corporatio...   \n",
              "4  [{'symbol': 'SBKFF', 'name': 'State Bank of In...   \n",
              "5  [{'symbol': 'QQQX', 'name': 'Nuveen Nasdaq 100...   \n",
              "6  [{'symbol': 'C', 'name': 'Citigroup Inc.', 'ex...   \n",
              "7  [{'symbol': 'DOW', 'name': 'Dow Inc.', 'exchan...   \n",
              "8  [{'symbol': 'MEG', 'name': 'Montrose Environme...   \n",
              "9  [{'symbol': 'GOOG', 'name': 'Alphabet Inc.', '...   \n",
              "\n",
              "                                             similar  sentiment  \\\n",
              "0                                                 []    0.00000   \n",
              "1                                                 []    0.00000   \n",
              "2                                                 []    0.69080   \n",
              "3                                                 []   -0.36120   \n",
              "4                                                 []    0.00000   \n",
              "5                                                 []    0.37150   \n",
              "6  [{'uuid': 'd359704e-cc4f-4e18-a564-f8e189eae75...   -0.63690   \n",
              "7  [{'uuid': 'c8cdbd28-1e3c-45f5-9333-66b6b389aee...    0.00000   \n",
              "8                                                 []    0.49770   \n",
              "9                                                 []    0.61495   \n",
              "\n",
              "                                                text  length  \\\n",
              "0  vzphotos/iStock Editorial via Getty Images\\n\\n...      42   \n",
              "1  Why I'm Doubling Down On My Adobe Position (NA...       1   \n",
              "2  And just like that... December is upon us. It'...     493   \n",
              "3  KEY ISSUES\\n\\nSilver surged 13% for the week a...     729   \n",
              "4  The combined market valuation of seven of the ...     254   \n",
              "5  QQQX: Tax-Efficient Dividends From The Nasdaq-...       1   \n",
              "6  It seems like you're already an ETPrime member...      41   \n",
              "7  Dow Stock: Approaching A Bottom But Recovery W...       1   \n",
              "8  Montrose Environmental Stock Looks Good Despit...       1   \n",
              "9  The Deal With Meta, Google Stock’s AI Chips To...       1   \n",
              "\n",
              "                                          clean_text  \n",
              "0  vzphotos istock editorial via getty images sin...  \n",
              "1  doubling adobe position nasdaq adbe adobe reve...  \n",
              "2  like december upon us volatile handover novemb...  \n",
              "3  key issues silver surged 13 week 90 year date ...  \n",
              "4  combined market valuation seven top 10 valued ...  \n",
              "5  qqqx tax efficient dividends nasdaq 100 nasdaq...  \n",
              "6  seems like already etprime member login using ...  \n",
              "7  dow stock approaching bottom recovery gradual ...  \n",
              "8  montrose environmental stock looks good despit...  \n",
              "9  deal meta google stock ai chips power new cycl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36b2ef7f-fce2-4e5a-8d8c-670d4b3392ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>keywords</th>\n",
              "      <th>snippet</th>\n",
              "      <th>url</th>\n",
              "      <th>image_url</th>\n",
              "      <th>language</th>\n",
              "      <th>published_at</th>\n",
              "      <th>source</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>entities</th>\n",
              "      <th>similar</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>487e6a88-d3c2-4ae1-8dc2-26af6b31d688</td>\n",
              "      <td>2025: The Year Of Alphabet (GOOG)</td>\n",
              "      <td>No stock has seen a bigger jump recently than ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vzphotos/iStock Editorial via Getty Images\\n\\n...</td>\n",
              "      <td>https://seekingalpha.com/article/4848680-2025-...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:30:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'GOOGL', 'name': 'Alphabet Inc.', ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>vzphotos/iStock Editorial via Getty Images\\n\\n...</td>\n",
              "      <td>42</td>\n",
              "      <td>vzphotos istock editorial via getty images sin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92b5c2bd-d324-4ae8-b115-2cfd95a8fa98</td>\n",
              "      <td>Why I'm Doubling Down On My Adobe Position (NA...</td>\n",
              "      <td>Adobe's revenue is highly predictable, driven ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To say that Adobe ( ADBE ) stock has not had a...</td>\n",
              "      <td>https://seekingalpha.com/article/4848762-why-i...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:25:01.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'ADBE', 'name': 'Adobe Inc.', 'exc...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Why I'm Doubling Down On My Adobe Position (NA...</td>\n",
              "      <td>1</td>\n",
              "      <td>doubling adobe position nasdaq adbe adobe reve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9084e5f1-75f5-4f15-aa3d-0676073b4aaf</td>\n",
              "      <td>Global week ahead: The start of a Santa Rally ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>STOXX 600, business news</td>\n",
              "      <td>And just like that... December is upon us. It'...</td>\n",
              "      <td>https://www.cnbc.com/2025/11/30/global-week-ah...</td>\n",
              "      <td>https://image.cnbcfm.com/api/v1/image/10823257...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:10:58.000000Z</td>\n",
              "      <td>cnbc.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'M', 'name': \"Macy's, Inc.\", 'exch...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.69080</td>\n",
              "      <td>And just like that... December is upon us. It'...</td>\n",
              "      <td>493</td>\n",
              "      <td>like december upon us volatile handover novemb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7d36a275-f3a3-44ea-8cbc-caa0d67749c4</td>\n",
              "      <td>Global Risk Monitor: Week in Review – Nov 28</td>\n",
              "      <td>KEY ISSUES Silver surged 13% for the week and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KEY ISSUES\\n\\nSilver surged 13% for the week a...</td>\n",
              "      <td>https://global-macro-monitor.com/2025/11/29/gl...</td>\n",
              "      <td>https://global-macro-monitor.com/wp-content/up...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:07:50.000000Z</td>\n",
              "      <td>global-macro-monitor.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'NVDA', 'name': 'NVIDIA Corporatio...</td>\n",
              "      <td>[]</td>\n",
              "      <td>-0.36120</td>\n",
              "      <td>KEY ISSUES\\n\\nSilver surged 13% for the week a...</td>\n",
              "      <td>729</td>\n",
              "      <td>key issues silver surged 13 week 90 year date ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42ba634c-b7ce-491a-91c0-e2b1424af827</td>\n",
              "      <td>Mcap boost: 7 of top-10 firms gain ₹96,201 cr;...</td>\n",
              "      <td>Market valuations of seven top firms rose by ₹...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The combined market valuation of seven of the ...</td>\n",
              "      <td>https://www.thehindubusinessline.com/markets/m...</td>\n",
              "      <td>https://bl-i.thgim.com/public/incoming/ji6cih/...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:04:20.000000Z</td>\n",
              "      <td>thehindubusinessline.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'SBKFF', 'name': 'State Bank of In...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>The combined market valuation of seven of the ...</td>\n",
              "      <td>254</td>\n",
              "      <td>combined market valuation seven top 10 valued ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>47000f09-22ab-4309-9411-c0c738327c25</td>\n",
              "      <td>QQQX: Tax-Efficient Dividends From The Nasdaq-...</td>\n",
              "      <td>Discover why Nuveen NASDAQ 100 Dynamic Overwri...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>With the rise of covered call ETFs, it can be ...</td>\n",
              "      <td>https://seekingalpha.com/article/4848757-qqqx-...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:23:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'QQQX', 'name': 'Nuveen Nasdaq 100...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.37150</td>\n",
              "      <td>QQQX: Tax-Efficient Dividends From The Nasdaq-...</td>\n",
              "      <td>1</td>\n",
              "      <td>qqqx tax efficient dividends nasdaq 100 nasdaq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>927ce408-c559-4f17-b673-37b0e9e301d7</td>\n",
              "      <td>Wall Street predicts rebound in Indian markets...</td>\n",
              "      <td>Wall Street giants anticipate a rebound for In...</td>\n",
              "      <td>Indian markets rebound, Morgan Stanley India f...</td>\n",
              "      <td>Live Events\\n\\nBloomberg\\n\\nBloomberg\\n\\nRBI S...</td>\n",
              "      <td>https://economictimes.indiatimes.com/markets/s...</td>\n",
              "      <td>https://img.etimg.com/thumb/msid-125668199,wid...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:14:43.000000Z</td>\n",
              "      <td>economictimes.indiatimes.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'C', 'name': 'Citigroup Inc.', 'ex...</td>\n",
              "      <td>[{'uuid': 'd359704e-cc4f-4e18-a564-f8e189eae75...</td>\n",
              "      <td>-0.63690</td>\n",
              "      <td>It seems like you're already an ETPrime member...</td>\n",
              "      <td>41</td>\n",
              "      <td>seems like already etprime member login using ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8eaf98bd-e728-4d9b-8d4b-013a8c66a173</td>\n",
              "      <td>Dow Stock: Approaching A Bottom But Recovery W...</td>\n",
              "      <td>Dow faces weak demand and excess capacity, but...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Shares of Dow have been a very poor performer ...</td>\n",
              "      <td>https://seekingalpha.com/article/4848756-dow-a...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:08:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'DOW', 'name': 'Dow Inc.', 'exchan...</td>\n",
              "      <td>[{'uuid': 'c8cdbd28-1e3c-45f5-9333-66b6b389aee...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Dow Stock: Approaching A Bottom But Recovery W...</td>\n",
              "      <td>1</td>\n",
              "      <td>dow stock approaching bottom recovery gradual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11f67276-4330-4c68-83ad-2599ec9711b2</td>\n",
              "      <td>Montrose Environmental Stock Looks Good Despit...</td>\n",
              "      <td>Discover why Montrose Environmental Group (MEG...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Robert F. Abbott has been investing his family...</td>\n",
              "      <td>https://seekingalpha.com/article/4848754-montr...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T03:38:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'MEG', 'name': 'Montrose Environme...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.49770</td>\n",
              "      <td>Montrose Environmental Stock Looks Good Despit...</td>\n",
              "      <td>1</td>\n",
              "      <td>montrose environmental stock looks good despit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4800cdcb-c5b0-4055-b3c8-a71dd23d8a6e</td>\n",
              "      <td>The Deal With Meta, Google Stock’s AI Chips To...</td>\n",
              "      <td>Discover why Alphabet is rated a Strong Buy as...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alphabet Inc. ( GOOG ) ( GOOGL ) is on a fanta...</td>\n",
              "      <td>https://seekingalpha.com/article/4848753-the-d...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T03:23:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'GOOG', 'name': 'Alphabet Inc.', '...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.61495</td>\n",
              "      <td>The Deal With Meta, Google Stock’s AI Chips To...</td>\n",
              "      <td>1</td>\n",
              "      <td>deal meta google stock ai chips power new cycl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36b2ef7f-fce2-4e5a-8d8c-670d4b3392ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36b2ef7f-fce2-4e5a-8d8c-670d4b3392ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36b2ef7f-fce2-4e5a-8d8c-670d4b3392ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-604e2a32-272f-4fb5-a09f-4f594dfdf790\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-604e2a32-272f-4fb5-a09f-4f594dfdf790')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-604e2a32-272f-4fb5-a09f-4f594dfdf790 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news_data",
              "summary": "{\n  \"name\": \"news_data\",\n  \"rows\": 9067,\n  \"fields\": [\n    {\n      \"column\": \"uuid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9057,\n        \"samples\": [\n          \"895f7a63-0fe8-431d-994d-b905a848bf7d\",\n          \"7458c578-eb7c-496d-b5c6-ad8cb0b9a10e\",\n          \"652e6d5a-3227-4cf6-8568-4c0e0818e497\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8881,\n        \"samples\": [\n          \"Union Pacific profits rise on operational efficiency, pricing gains\",\n          \"How Is Morgan Stanley's Stock Performance Compared to Other Capital Market Stocks\",\n          \"Intel Corporation (INTC) is Attracting Investor Attention: Here is What You Should Know\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8387,\n        \"samples\": [\n          \"Amazon's\\u00a0You buy. We donate.\\u00a0campaign is returning to help tackle hygiene poverty in the UK.\",\n          \"VANCOUVER, British Columbia, Oct. 30, 2025 (GLOBE NEWSWIRE) -- Xali Gold Corp. (TSXV:XGC) ('Xali Gold\\u201d or the 'Company\\u201d) announces that certain directors, officers, employees and consultants of the Company have been granted incentive stock options to purchase 2,200,000 common shares of Xali Gold at an exercise price equal to $0.05 per share. The options have a 5-year term, expiring October 30, 2030.\",\n          \"2025-10-28. The following slide deck was published by MSCI Inc.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3229,\n        \"samples\": [\n          \"Tidewater Inc., offshore support vessels, offshore energy industry, Tidewater, revenue guidance, marine support, marine service\",\n          \"KLN, Named, Exclusive, Distributor, for, Siemens, Healthineers\",\n          \"Larsen & Toubro, General Atomics, unmanned aircraft, MALE drones, defence ecosystem, defence manufacturing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6433,\n        \"samples\": [\n          \"Trading houses, hedge funds and banks are on a hiring spree for specialist gold traders as interest in the metal soars, creating a battle for talent that is dri...\",\n          \"Galeanu Mihai/iStock via Getty Images\\n\\nDear Partners,\\n\\nI am pleased to report that Alluvial Fund produced a return of 15.5% in the third quarter, bringing our 2...\",\n          \"Net Profit Surges 45.4% YoY in 3Q 2025\\n\\nHONG KONG, SHANGHAI, Oct. 28, 2025 /PRNewswire/ -- Ping An Insurance (Group) Company of China, Ltd. (hereafter \\\"Ping An\\\"...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9057,\n        \"samples\": [\n          \"https://www.manilatimes.net/2025/10/27/tmt-newswire/globenewswire/neumora-therapeutics-announces-initiation-of-phase-1-clinical-study-of-m4-positive-allosteric-modulator-nmra-898/2208967\",\n          \"https://finance.yahoo.com/news/ubs-lowers-airbnb-abnb-pt-133046220.html\",\n          \"https://seekingalpha.com/article/4833093-eastern-bankshares-inc-2025-q3-results-earnings-call-presentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5782,\n        \"samples\": [\n          \"https://static.seekingalpha.com/cdn/s3/uploads/getty_images/1418324628/image_1418324628.jpg?io=getty-c-w630\",\n          \"https://staticx-tuner.zacks.com/images/default_article_images/default269.jpg\",\n          \"https://argaamplus.s3.amazonaws.com/53404d14-48b9-4750-ba69-93d386c1ecc9.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"published_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8562,\n        \"samples\": [\n          \"2025-10-27T10:36:42.000000Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 180,\n        \"samples\": [\n          \"businessinsider.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9042,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similar\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1548,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30891443478745234,\n        \"min\": -0.9042,\n        \"max\": 0.9858,\n        \"num_unique_values\": 3327,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7883,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 789,\n        \"min\": 1,\n        \"max\": 12606,\n        \"num_unique_values\": 1315,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7879,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "news_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9cd4177",
      "metadata": {
        "id": "b9cd4177"
      },
      "source": [
        "## Clean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61098227",
      "metadata": {
        "id": "61098227"
      },
      "source": [
        "### Check for Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "960758c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "960758c2",
        "outputId": "50a3af40-2395-4672-90e7-49ed421cd9fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Number_Missing  Missing_Percentage\n",
            "uuid                          0            0.000000\n",
            "title                         0            0.000000\n",
            "description                 414            4.566009\n",
            "keywords                   4774           52.652476\n",
            "snippet                      37            0.408073\n",
            "url                           0            0.000000\n",
            "image_url                    36            0.397044\n",
            "language                      0            0.000000\n",
            "published_at                  0            0.000000\n",
            "source                        0            0.000000\n",
            "relevance_score            9067          100.000000\n",
            "entities                      0            0.000000\n",
            "similar                       0            0.000000\n",
            "sentiment                     0            0.000000\n",
            "text                          0            0.000000\n",
            "length                        0            0.000000\n",
            "clean_text                    0            0.000000\n"
          ]
        }
      ],
      "source": [
        "is_na = pd.DataFrame(news_data.isna().sum())\n",
        "is_na.columns = [\"Number_Missing\"]\n",
        "is_na[\"Missing_Percentage\"] = (is_na[\"Number_Missing\"] / len(news_data) * 100)\n",
        "print(is_na)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f1c8b6",
      "metadata": {
        "id": "56f1c8b6"
      },
      "source": [
        "### Check for Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1402a818",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1402a818",
        "outputId": "5b4057b3-15ac-4e5e-a37e-88b198d0db17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "news_data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bff61d1",
      "metadata": {
        "id": "0bff61d1"
      },
      "source": [
        "## Split the Data to Train, Test, and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "01d36764",
      "metadata": {
        "id": "01d36764"
      },
      "outputs": [],
      "source": [
        "test_size = 0.20\n",
        "val_size = 0.10\n",
        "\n",
        "# Splitting the data into train and temp (which will be further split into validation and test)\n",
        "train_df, test_df = train_test_split(news_data, test_size=test_size, random_state=SEED)\n",
        "\n",
        "# Splitting train into validation and test sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=val_size, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff104da1",
      "metadata": {
        "id": "ff104da1"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78b88cc",
      "metadata": {
        "id": "c78b88cc"
      },
      "source": [
        "### Word Tokenization\n",
        "\n",
        "the words in the sentence would be tokenized since gensim's fasttext model requires the sentence to be tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "43969a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43969a98",
        "outputId": "0ab0d5ae-304a-4cd4-b921-f92b94d2f263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing Train Data...: 100%|██████████| 6527/6527 [00:30<00:00, 216.97news/s]\n",
            "Preprocessing Test Data...: 100%|██████████| 1814/1814 [00:09<00:00, 195.08news/s]\n",
            "Preprocessing Validation Data...: 100%|██████████| 726/726 [00:03<00:00, 224.79news/s]\n"
          ]
        }
      ],
      "source": [
        "# tqdm for cleaner output\n",
        "tqdm.pandas(desc=\"Preprocessing Train Data...\", unit=\"news\")\n",
        "train_df[\"tokenized_text\"] = train_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Preprocessing Test Data...\", unit=\"news\")\n",
        "test_df[\"tokenized_text\"] = test_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Preprocessing Validation Data...\", unit=\"news\")\n",
        "val_df[\"tokenized_text\"] = val_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d436c5c1",
      "metadata": {
        "id": "d436c5c1"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8b1a58",
      "metadata": {
        "id": "7e8b1a58"
      },
      "source": [
        "### Train FastText Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "554eeece",
      "metadata": {
        "id": "554eeece"
      },
      "outputs": [],
      "source": [
        "ft_model = FastText(\n",
        "    sentences=train_df[\"tokenized_text\"],\n",
        "    vector_size=300,    # size of embedding\n",
        "    window=5,           # Window size\n",
        "    min_count=0,        # Since currently there is a low amount of data and some financial\n",
        "                        # terms doesent appear frequentlywe would set this to 0\n",
        "    sg=1,               # skip-gram since some of the financial terms are rare\n",
        "    min_n=3,            # generate all n-grams (e.g. Hello -> \"hel\", \"ell\", \"llo\") so fasttext can understand typos\n",
        "    max_n=8,            # max n-grams\n",
        "    seed=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea353aa",
      "metadata": {
        "id": "aea353aa"
      },
      "source": [
        "### Apply FastText to the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5184a23d",
      "metadata": {
        "id": "5184a23d"
      },
      "outputs": [],
      "source": [
        "# sentence vector function\n",
        "\n",
        "def get_vectors(tokens: list[str]):\n",
        "    return [ft_model.wv.get_vector(word) for word in tokens if word in ft_model.wv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "847b6c45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "847b6c45",
        "outputId": "df175334-0af1-473b-a170-95ca6559f57b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Vectorizing Train Data...: 100%|██████████| 6527/6527 [00:01<00:00, 3817.88news/s]\n",
            "Vectorizing Test Data...: 100%|██████████| 1814/1814 [00:00<00:00, 2163.71news/s]\n",
            "Vectorizing Validation Data...: 100%|██████████| 726/726 [00:00<00:00, 2454.36news/s]\n"
          ]
        }
      ],
      "source": [
        "# tqdm for cleaner output\n",
        "tqdm.pandas(desc=\"Vectorizing Train Data...\", unit=\"news\")\n",
        "train_df[\"vectorized_text\"] = train_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Vectorizing Test Data...\", unit=\"news\")\n",
        "test_df[\"vectorized_text\"] = test_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Vectorizing Validation Data...\", unit=\"news\")\n",
        "val_df[\"vectorized_text\"] = val_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c554397",
      "metadata": {
        "id": "1c554397"
      },
      "source": [
        "## Split the X and Y values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0e5912bc",
      "metadata": {
        "id": "0e5912bc"
      },
      "outputs": [],
      "source": [
        "x_train = train_df[\"vectorized_text\"]\n",
        "x_test = test_df[\"vectorized_text\"]\n",
        "x_val = val_df[\"vectorized_text\"]\n",
        "\n",
        "y_train = train_df[\"sentiment\"].to_numpy()\n",
        "y_test = test_df[\"sentiment\"].to_numpy()\n",
        "y_val = val_df[\"sentiment\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fe356e02",
      "metadata": {
        "id": "fe356e02"
      },
      "outputs": [],
      "source": [
        "# # get sample because run on laptop\n",
        "# x_train_sample = x_train[:64]\n",
        "# x_test_sample = x_test[:64]\n",
        "# x_val_sample = x_val[:64]\n",
        "\n",
        "# y_train_sample = y_train[:64]\n",
        "# y_test_sample = y_test[:64]\n",
        "# y_val_sample = y_val[:64]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ac814e",
      "metadata": {
        "id": "62ac814e"
      },
      "source": [
        "## Apply Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5d1f92b6",
      "metadata": {
        "id": "5d1f92b6"
      },
      "outputs": [],
      "source": [
        "# Padding Function\n",
        "def pad_sequences(vectorized_sentences, max_len=300):\n",
        "    padded_list = []\n",
        "\n",
        "    for vec in vectorized_sentences:\n",
        "        vec = torch.tensor(vec, dtype=torch.float32)\n",
        "\n",
        "        # Truncate if too long\n",
        "        if vec.shape[0] > max_len:\n",
        "            vec = vec[:max_len]\n",
        "\n",
        "        # Pad if too short\n",
        "        if vec.shape[0] < max_len:\n",
        "            pad_length = max_len - vec.shape[0]\n",
        "            padding = torch.zeros((pad_length, vec.shape[1]))  # (pad_len, embedding_dim)\n",
        "            vec = torch.cat([vec, padding], dim=0)  # post-padding\n",
        "\n",
        "        padded_list.append(vec)\n",
        "\n",
        "    return torch.stack(padded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b9db4712",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9db4712",
        "outputId": "1534b04a-f427-4d31-eec5-c77b1b2c0c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2428613510.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  vec = torch.tensor(vec, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "max_padding_len = 300\n",
        "\n",
        "x_train_vectors = x_train.tolist()\n",
        "x_train_padded = pad_sequences(x_train_vectors, max_len = max_padding_len)\n",
        "x_train_padded = x_train_padded.numpy()\n",
        "\n",
        "x_test_vectors = x_test.tolist()\n",
        "x_test_padded = pad_sequences(x_test_vectors, max_len = max_padding_len)\n",
        "x_test_padded = x_test_padded.numpy()\n",
        "\n",
        "x_val_vectors = x_val.tolist()\n",
        "x_val_padded = pad_sequences(x_val_vectors, max_len = max_padding_len)\n",
        "x_val_padded = x_val_padded.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca3a5a3",
      "metadata": {
        "id": "eca3a5a3"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "af6601a6",
      "metadata": {
        "id": "af6601a6"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Train data\n",
        "x_train_tensor = torch.tensor(x_train_padded, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# test data\n",
        "x_test_tensor = torch.tensor(x_test_padded, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# val data\n",
        "x_val_tensor = torch.tensor(x_val_padded, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b5828b",
      "metadata": {
        "id": "79b5828b"
      },
      "source": [
        "## Build LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0107a86",
      "metadata": {
        "id": "c0107a86"
      },
      "source": [
        "### Model Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a98097dc",
      "metadata": {
        "id": "a98097dc"
      },
      "outputs": [],
      "source": [
        "def define_model(trial, input_size, n_output):\n",
        "    class GridLSTM(nn.Module):\n",
        "        def __init__(self, trial, input_size: int, hidden_size: int, num_layers: int, n_output: int):\n",
        "            super().__init__()\n",
        "\n",
        "            def dense_layer_builder(layer_prefix):\n",
        "                nonlocal input_size, dense_layers\n",
        "\n",
        "                # Dense layer parameters\n",
        "                out_size = trial.suggest_int(f\"{layer_prefix}_output_size\", 32, 512)\n",
        "                dense_layers.append(nn.Linear(input_size, out_size))\n",
        "\n",
        "                # Add drop out rate so that it reduces overfitting and improve generlization\n",
        "                dropout_rate = trial.suggest_float(f\"{layer_prefix}_dropout_rate\", 0.0, 0.8)\n",
        "                if dropout_rate > 0:\n",
        "                    dense_layers.append(nn.Dropout(dropout_rate)) # Update input size for the next dense layer based on the output size of this one\n",
        "\n",
        "                input_size = out_size\n",
        "\n",
        "            if num_layers >= 3:\n",
        "                lstm_dropout = trial.suggest_float(\"lstm_dropout\", 0.0, 0.8)\n",
        "            else:\n",
        "                lstm_dropout = 0\n",
        "                trial.set_user_attr(\"lstm_dropout\", lstm_dropout)\n",
        "\n",
        "            self.hidden_size = hidden_size\n",
        "            self.num_layers = num_layers\n",
        "\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size = input_size,\n",
        "                hidden_size = hidden_size, #number of LSTM Blocks\n",
        "                num_layers = num_layers, #number of LSTM layers\n",
        "                batch_first = True, # so that pytorch recognizes the input to be [batch_size, sequence_length, input_size] otherwise [sequence_length, batch_size, input_size]\n",
        "                dropout = lstm_dropout\n",
        "            )\n",
        "\n",
        "            # Make the dense layers\n",
        "            dense_layers = []\n",
        "            input_size = hidden_size\n",
        "            n_dense_layers = trial.suggest_int(\"n_dense_layer\", 1, 20)\n",
        "\n",
        "            for i in range(n_dense_layers):\n",
        "                dense_layer_builder(f\"dense_{i}\") #input size would be updated each iteration\n",
        "\n",
        "            #output Layer\n",
        "            dense_layers.append(nn.Linear(input_size, n_output))\n",
        "\n",
        "            # Register dense layers as nn.Sequential\n",
        "            self.dense = nn.Sequential(*dense_layers)\n",
        "\n",
        "        def forward(self, input_tensor): # Forward pass\n",
        "            if input_tensor.dim() == 2:  # [seq_len, input_size] unbatched\n",
        "                input_tensor = input_tensor.unsqueeze(1)  # make [1, seq_len, input_size] if the dimensions\n",
        "                batch_size = input_tensor.size(0)\n",
        "                h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "                c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            else:  # [batch_size, seq_len, input_size]\n",
        "                batch_size = input_tensor.size(0)\n",
        "                h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "                c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            out, _ = self.lstm(input_tensor, (h0, c0))  # LSTM forward\n",
        "            out = self.dense(out[:, -1, :])             # Take last time step and pass through dense\n",
        "            return out\n",
        "\n",
        "    hidden_size = trial.suggest_int(\"lstm_hidden_size\", 8, 512)\n",
        "    num_layers = trial.suggest_int(\"lstm_num_layers\", 1, 6)\n",
        "    return GridLSTM(trial, input_size, hidden_size, num_layers, n_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da715301",
      "metadata": {
        "id": "da715301"
      },
      "source": [
        "### Optuna Objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "69054d08",
      "metadata": {
        "id": "69054d08"
      },
      "outputs": [],
      "source": [
        "def objective(trial, n_input, n_output, train_loader, val_loader, epochs, device):\n",
        "    # Reset the seed for each trial of the gridsearch\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    # Parameters for early stopping\n",
        "    best_mse = inf # Inital MSE score\n",
        "    patience = 3 # number of epochs to wait without improvement before stopping\n",
        "    epochs_no_improve = 0 # Epochs counter without improvement\n",
        "    best_model_state = None # To store the best model weights\n",
        "\n",
        "    # Model Initialization\n",
        "    model = define_model(trial, n_input, n_output).to(device)\n",
        "\n",
        "    # Learning rate\n",
        "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)  # log-scale search\n",
        "\n",
        "    # Optimizer Set-Up\n",
        "    optimizer_name = trial.suggest_categorical(\"Optimizer\", [\"Adam\", \"Momentum\", \"AdamW\"])\n",
        "    optimizer = {\n",
        "        \"Adam\": optim.Adam(model.parameters(), lr=lr),\n",
        "        \"Momentum\": optim.SGD(model.parameters(),\n",
        "                            lr=lr,\n",
        "                            momentum=trial.suggest_float(\"sgd_momentum\", 1e-5, 5e-3, log=True)),\n",
        "        \"AdamW\": optim.AdamW(model.parameters(),\n",
        "                            lr=lr,\n",
        "                            weight_decay=trial.suggest_float(\"adamw_weight_decay\", 1e-5, 5e-3, log=True))\n",
        "    }[optimizer_name]\n",
        "\n",
        "    # Loss function\n",
        "    loss_function = nn.MSELoss() # This is to punish the model for large errors\n",
        "\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training model...\"):\n",
        "        # Training loop\n",
        "        model.train()\n",
        "        for inputs, true_values in train_loader:\n",
        "            inputs, true_values = inputs.to(device), true_values.to(device) # Set the device to train on\n",
        "\n",
        "            optimizer.zero_grad() # Resets all the gradients since pytorch accumulates gradients from previous training\n",
        "            outputs = model(inputs) # Runs a forward pass\n",
        "            loss = loss_function(outputs.view(-1), true_values.view(-1)) # Calculates the error\n",
        "            loss.backward() # Runs a Backward pass\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) #prevents exploding gradient\n",
        "            optimizer.step() # Updates model trainable parameters\n",
        "\n",
        "        # Early Stopping Check\n",
        "        # Validation (after training loop finishes)\n",
        "        model.eval() # Make model in evaluation mode\n",
        "        all_preds = [] # For the model predictions and true lables\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad(): # Turns off gradient tracking for speeding up validation, saves memory, lock memory weights\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device).float(), labels.to(device).float() # move lables to the device\n",
        "                outputs = model(inputs) # Pass input data to the model to get raw logits\n",
        "\n",
        "                all_preds.extend(outputs.squeeze().cpu().numpy()) # move the predictions and lables to the cpu since numpy only works on CPU memory. then convert to numpy arrays then append to the list.\n",
        "                all_labels.extend(labels.squeeze().cpu().numpy())\n",
        "\n",
        "        # Calculate MSE Score\n",
        "        curr_mse = mean_squared_error(all_labels, all_preds) # Calculate mse score\n",
        "\n",
        "        if curr_mse < best_mse:\n",
        "            best_mse = curr_mse\n",
        "            epochs_no_improve = 0\n",
        "            best_model_state = deepcopy(model.state_dict()) # Save the model state\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                tqdm.write(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    # Load best model weights for reporting\n",
        "    model.load_state_dict(best_model_state)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad(): # Turns off gradient tracking for speeding up validation, saves memory, lock memory weights\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move lables to the device\n",
        "            outputs = model(inputs) # Pass input data to the model to get raw logits\n",
        "\n",
        "            all_preds.extend(outputs.squeeze().cpu().numpy()) # move the predictions and lables to the cpu since numpy only works on CPU memory. then convert to numpy arrays then append to the list.\n",
        "            all_labels.extend(labels.squeeze().cpu().numpy())\n",
        "\n",
        "    best_mse = mean_squared_error(all_labels, all_preds)\n",
        "    tqdm.write(f\"Trial {trial.number}: Best MSE Score = {best_mse:.4f}\")\n",
        "    trial.set_user_attr(\"best_model_state\", best_model_state)\n",
        "    return best_mse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eae52f0",
      "metadata": {
        "id": "2eae52f0"
      },
      "source": [
        "### Initialte Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "98b999b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "id": "98b999b0",
        "outputId": "84299787-f547-4261-f775-f6b7780ab4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training model...:   0%|          | 0/40 [00:05<?, ?it/s]\n",
            "[W 2025-12-22 16:38:38,431] Trial 16 failed with parameters: {'lstm_hidden_size': 159, 'lstm_num_layers': 3, 'lstm_dropout': 0.038071522708039755, 'n_dense_layer': 20, 'dense_0_output_size': 204, 'dense_0_dropout_rate': 0.14439437849347928, 'dense_1_output_size': 148, 'dense_1_dropout_rate': 0.0029578877938125636, 'dense_2_output_size': 277, 'dense_2_dropout_rate': 0.31836965389694827, 'dense_3_output_size': 75, 'dense_3_dropout_rate': 0.12899147626540897, 'dense_4_output_size': 480, 'dense_4_dropout_rate': 0.43294239780146393, 'dense_5_output_size': 454, 'dense_5_dropout_rate': 0.16564909870311012, 'dense_6_output_size': 278, 'dense_6_dropout_rate': 0.6722340684271815, 'dense_7_output_size': 452, 'dense_7_dropout_rate': 0.07330865460494387, 'dense_8_output_size': 133, 'dense_8_dropout_rate': 0.6157184429084944, 'dense_9_output_size': 33, 'dense_9_dropout_rate': 0.04244665788370137, 'dense_10_output_size': 119, 'dense_10_dropout_rate': 0.0707145092156412, 'dense_11_output_size': 44, 'dense_11_dropout_rate': 0.5505676784378956, 'dense_12_output_size': 80, 'dense_12_dropout_rate': 0.032896583250843214, 'dense_13_output_size': 374, 'dense_13_dropout_rate': 0.12411791824449736, 'dense_14_output_size': 459, 'dense_14_dropout_rate': 0.029696899558401046, 'dense_15_output_size': 179, 'dense_15_dropout_rate': 0.7007551345554586, 'dense_16_output_size': 53, 'dense_16_dropout_rate': 0.3665475576857129, 'dense_17_output_size': 365, 'dense_17_dropout_rate': 0.17740065525844104, 'dense_18_output_size': 114, 'dense_18_dropout_rate': 0.38864520500910804, 'dense_19_output_size': 338, 'dense_19_dropout_rate': 0.3262845570725677, 'learning_rate': 0.0904536195593911, 'Optimizer': 'AdamW', 'sgd_momentum': 1.7578738385073425e-05, 'adamw_weight_decay': 0.000304169373208776} because of the following error: ValueError('Input contains NaN.').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2639905994.py\", line 18, in <lambda>\n",
            "    study.optimize(lambda trial: objective(trial,input_size, output_size, train_loader,\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-4244853533.py\", line 62, in objective\n",
            "    curr_mse = mean_squared_error(all_labels, all_preds) # Calculate mse score\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\", line 565, in mean_squared_error\n",
            "    _check_reg_targets_with_floating_dtype(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\", line 198, in _check_reg_targets_with_floating_dtype\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "                                          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\", line 106, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\", line 1107, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
            "    _assert_all_finite_element_wise(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "[W 2025-12-22 16:38:38,434] Trial 16 failed with value None.\n",
            "Gridsearch ...:  16%|█▌        | 16/100 [10:50<56:56, 40.67s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2639905994.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#wait for .8 seconds befor clearing the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# comment this out of you want to see the whole training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     study.optimize(lambda trial: objective(trial,input_size, output_size, train_loader,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             val_loader, epochs, device),\n\u001b[1;32m     20\u001b[0m                     n_trials=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mfrozen_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     ):\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2639905994.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#wait for .8 seconds befor clearing the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# comment this out of you want to see the whole training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     study.optimize(lambda trial: objective(trial,input_size, output_size, train_loader,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             val_loader, epochs, device),\n\u001b[1;32m     20\u001b[0m                     n_trials=1)\n",
            "\u001b[0;32m/tmp/ipython-input-4244853533.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, n_input, n_output, train_loader, val_loader, epochs, device)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Calculate MSE Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mcurr_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate mse score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurr_mse\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_mse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[0;32m--> 565\u001b[0;31m         _check_reg_targets_with_floating_dtype(\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdtype_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_matching_floating_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ],
      "source": [
        "# The input size\n",
        "input_size = x_train_padded.shape[2]\n",
        "\n",
        "# Get number of outputs\n",
        "output_size = 1 # since this is regression there would be only 1 output\n",
        "epochs = 40\n",
        "n_trials = 100\n",
        "\n",
        "samplers = optuna.samplers.TPESampler(n_startup_trials=20) # Bayesian optimization method used by Optuna to sample hyperparameters intelligently (20 random trials first before starting the Bayesian optimization.)\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=samplers) # Minimize MSE score\n",
        "\n",
        "# Tqdm for cleaner output\n",
        "progress_bar = tqdm(total=n_trials, desc=\"Trial\", ncols=80)\n",
        "\n",
        "for _ in tqdm(range(n_trials), desc=\"Gridsearch ...\"):\n",
        "    time.sleep(0.8) #wait for .8 seconds befor clearing the output\n",
        "    clear_output(wait=True) # comment this out of you want to see the whole training process\n",
        "    study.optimize(lambda trial: objective(trial,input_size, output_size, train_loader,\n",
        "                                            val_loader, epochs, device),\n",
        "                    n_trials=1)\n",
        "\n",
        "# Summarize study results\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED]) # get the pruned trials\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE]) # get the succeeded trials\n",
        "\n",
        "print(\"\\nstudy statistics:\")\n",
        "print(f\"  Finished trials: {len(study.trials)}\")\n",
        "print(f\"  Pruned trials:   {len(pruned_trials)}\")\n",
        "print(f\"  Complete trials: {len(complete_trials)}\")\n",
        "\n",
        "# Define model with best params\n",
        "best_trial = study.best_trial\n",
        "print(\"Best trial:\")\n",
        "print(f\"  Best MSE: {best_trial.value:.4f}\")\n",
        "best_model = define_model(best_trial, input_size, output_size).to(device)\n",
        "\n",
        "# Load best weights\n",
        "best_model.load_state_dict(best_trial.user_attrs[\"best_model_state\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75e65b7",
      "metadata": {
        "id": "d75e65b7"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "874e9ce5",
      "metadata": {
        "id": "874e9ce5"
      },
      "source": [
        "### Model Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e52b5aa",
      "metadata": {
        "id": "0e52b5aa"
      },
      "outputs": [],
      "source": [
        "# Model Builder from Parameters\n",
        "def define_model_from_params(params: dict, input_size: int, n_output: int):\n",
        "    class GridLSTM(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            self.hidden_size = params[\"lstm_hidden_size\"]\n",
        "            self.num_layers = params[\"lstm_num_layers\"]\n",
        "            self.lstm_dropout = params.get(\"lstm_dropout\", 0.0)\n",
        "\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                batch_first=True,\n",
        "                dropout=self.lstm_dropout\n",
        "            )\n",
        "\n",
        "            # Build dense layers\n",
        "            dense_layers = []\n",
        "            dense_input_size = self.lstm.hidden_size\n",
        "            n_dense_layers = params.get(\"n_dense_layer\", 1)\n",
        "\n",
        "            for i in range(n_dense_layers):\n",
        "                out_size = params[f\"dense_{i}_output_size\"]\n",
        "                dense_layers.append(nn.Linear(dense_input_size, out_size))\n",
        "\n",
        "                dropout_rate = params.get(f\"dense_{i}_dropout_rate\", 0.0)\n",
        "                if dropout_rate > 0:\n",
        "                    dense_layers.append(nn.Dropout(dropout_rate))\n",
        "\n",
        "                dense_input_size = out_size\n",
        "\n",
        "            # Output layer\n",
        "            dense_layers.append(nn.Linear(dense_input_size, n_output))\n",
        "            self.dense = nn.Sequential(*dense_layers)\n",
        "\n",
        "        def forward(self, input_tensor):\n",
        "            if input_tensor.dim() == 2:  # [batch_size, input_size]\n",
        "                input_tensor = input_tensor.unsqueeze(1)  # make it [batch_size, seq_len=1, input_size]\n",
        "\n",
        "            batch_size = input_tensor.size(0)\n",
        "\n",
        "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            # LSTM Forward pass\n",
        "            out, _ = self.lstm(input_tensor, (h0, c0)) # out: [batch_size, seq_len, hidden_size]\n",
        "            out = self.dense(out[:, -1, :]) # take the last time step and pass it to the dense layer\n",
        "            return out\n",
        "\n",
        "    return GridLSTM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273c6bf7",
      "metadata": {
        "id": "273c6bf7"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            all_preds.extend(outputs.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "    # Compute metrics\n",
        "    mse = mean_squared_error(all_labels, all_preds)\n",
        "    mae = mean_absolute_error(all_labels, all_preds)\n",
        "    rmse = root_mean_squared_error(all_labels, all_preds)\n",
        "    r2 = r2_score(all_labels, all_preds)\n",
        "\n",
        "    return mse, mae, rmse, r2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9ac2820",
      "metadata": {
        "id": "e9ac2820"
      },
      "source": [
        "### Export and Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e289f630",
      "metadata": {
        "id": "e289f630"
      },
      "outputs": [],
      "source": [
        "model_pytorch_path = os.path.join(project_path,\"models/fast_text_lstm/fast_text_lstm_model.pt\")\n",
        "model_json_path = os.path.join(project_path,\"models/fast_text_lstm/fast_text_lstm_model.json\")\n",
        "seed_path = os.path.join(project_path,\"models/fast_text_lstm/seed.txt\")\n",
        "new_model = best_model.to(device)\n",
        "new_model.eval()\n",
        "\n",
        "# Evaluate new model on test set\n",
        "new_mse, new_mae, new_rmse, new_r2 = evaluate_model(\n",
        "                                    new_model,\n",
        "                                    test_loader,\n",
        "                                    device\n",
        "                                    )\n",
        "\n",
        "if os.path.exists(model_pytorch_path) and os.path.exists(model_json_path):\n",
        "    # Load the existing (old) model\n",
        "    with open(model_json_path, \"r\") as f:\n",
        "        best_old_params = json.load(f)\n",
        "\n",
        "    old_model = define_model_from_params(best_old_params, input_size, output_size).to(device)\n",
        "    old_model.load_state_dict(torch.load(model_pytorch_path))\n",
        "    old_model.eval()\n",
        "\n",
        "    # Evaluate the old model\n",
        "    old_mse, old_mae, old_rmse, old_r2 = evaluate_model(\n",
        "                                        old_model,\n",
        "                                        test_loader,\n",
        "                                        device\n",
        "                                        )\n",
        "    print(\"Model Scores:\")\n",
        "    print(f\"Old_mse       = {old_mse:.4f}     | New_mse       = {new_mse:.4f}\")\n",
        "    print(f\"Old_mae       = {old_mae:.4f}     | New_mae       = {new_mae:.4f}\")\n",
        "    print(f\"Old_rmse      = {old_rmse:.4f}    | New_rmse      = {new_rmse:.4f}\")\n",
        "    print(f\"Old_r²        = {old_r2:.4f}      | new_r²        = {new_r2:.4f}\")\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    if new_mse < old_mse:\n",
        "        print(\"🔁 New model is better — overwriting saved model.\")\n",
        "        torch.save(new_model.state_dict(), model_pytorch_path)\n",
        "\n",
        "        with open(model_json_path, \"w\") as f:\n",
        "            json.dump(best_trial.params, f, indent=4)\n",
        "\n",
        "        with open(seed_path, \"w\") as file:\n",
        "            file.write(str(SEED))\n",
        "\n",
        "        model = new_model\n",
        "        model_params = best_trial.params\n",
        "    else:\n",
        "        print(\"✅ Existing model is still better.\")\n",
        "        model = old_model\n",
        "        model_params = best_old_params\n",
        "else:\n",
        "    print(\"Model Score:\")\n",
        "    print(f\"New_mse       = {new_mse:.4f}\")\n",
        "    print(f\"New_mae       = {new_mae:.4f}\")\n",
        "    print(f\"New_rmse      = {new_rmse:.4f}\")\n",
        "    print(f\"new_r²        = {new_r2:.4f}\")\n",
        "    print()\n",
        "    print()\n",
        "    print(\"📥 No existing model — saving new model.\")\n",
        "    os.makedirs(os.path.join(project_path, \"models/word2vec_lstm/\"), exist_ok=True)\n",
        "    torch.save(new_model.state_dict(), model_pytorch_path)\n",
        "    with open(model_json_path, \"w\") as f:\n",
        "        json.dump(best_trial.params, f, indent=4)\n",
        "    with open(seed_path, \"w\") as file:\n",
        "        file.write(str(SEED))\n",
        "    model = new_model\n",
        "    model_params = best_trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0357ccf1",
      "metadata": {
        "id": "0357ccf1"
      },
      "outputs": [],
      "source": [
        "for key, value in model_params.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}