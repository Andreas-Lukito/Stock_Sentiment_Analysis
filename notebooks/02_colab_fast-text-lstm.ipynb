{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andreas-Lukito/Stock_Sentiment_Analysis/blob/dev%2Fandreas/notebooks/02_colab_fast-text-lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "215c2c9f",
      "metadata": {
        "id": "215c2c9f"
      },
      "source": [
        "# Fast Text + LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a0242b8",
      "metadata": {
        "id": "0a0242b8"
      },
      "source": [
        "## Instal Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "01650d9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01650d9d",
        "outputId": "26a69c97-da94-442a-d66b-50f8b8f3da2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, emoji, colorlog, anyascii, textsearch, gensim, optuna, contractions\n",
            "Successfully installed anyascii-0.3.3 colorlog-6.10.1 contractions-0.1.73 emoji-2.15.0 gensim-4.4.0 optuna-4.6.0 pyahocorasick-2.3.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "! pip install contractions emoji gensim optuna torch matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3009e5b7",
      "metadata": {
        "id": "3009e5b7"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e85e67af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e85e67af",
        "outputId": "d5933d14-eea3-411d-8488-52827a1452b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "seed: 3473626926\n"
          ]
        }
      ],
      "source": [
        "# Common Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Cleaner output\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Deep Learning Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import inf\n",
        "\n",
        "# Text Embedding Method\n",
        "from gensim.models import FastText\n",
        "\n",
        "# Data Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "## Download nltk dependencies\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Deep Learning Hyperparameter Tuning\n",
        "import optuna\n",
        "from optuna.exceptions import TrialPruned\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "# Model metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_path = \"/content/drive/MyDrive/stock_news_sentiment_analysis\"\n",
        "\n",
        "# Add the path to the text preprocessor\n",
        "sys.path.append(os.path.abspath(os.path.join(project_path, \"lib\")))\n",
        "\n",
        "## Import preprocessor\n",
        "from preprocessor import clean_text\n",
        "\n",
        "# Project Seed for Reproducability\n",
        "SEED = random.randint(0, 2**32 - 1)  # Random integer between 0 and 2^32-1\n",
        "print(f\"seed: {SEED}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f43bb5",
      "metadata": {
        "id": "12f43bb5"
      },
      "source": [
        "## GPU Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9627979d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9627979d",
        "outputId": "3a19cf95-f3ec-4694-8a7d-e424f89c8911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch is using GPU: NVIDIA A100-SXM4-80GB\n",
            "Backend: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Detect available device\n",
        "if torch.cuda.is_available():\n",
        "    # check if ROCm backend is active\n",
        "    if torch.version.hip is not None:\n",
        "        backend = \"ROCm\"\n",
        "    else:\n",
        "        backend = \"CUDA\"\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"PyTorch is using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Backend: {backend}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"PyTorch is not using GPU — running on CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19416b3a",
      "metadata": {
        "id": "19416b3a"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8ff49caa",
      "metadata": {
        "id": "8ff49caa"
      },
      "outputs": [],
      "source": [
        "before_date = \"2025-11\"\n",
        "\n",
        "# Data path\n",
        "cleaned_data_path = os.path.join(project_path,f\"news_cache/{before_date}/csv/\")\n",
        "clean_cached_file = os.path.join(cleaned_data_path, f\"{before_date}_clean_news_data.csv\")\n",
        "\n",
        "# Import Data\n",
        "news_data = pd.read_csv(filepath_or_buffer=clean_cached_file, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3e765dcf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3e765dcf",
        "outputId": "1243a634-34e2-4bf0-e900-5c134bfe63c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   uuid  \\\n",
              "0  487e6a88-d3c2-4ae1-8dc2-26af6b31d688   \n",
              "1  92b5c2bd-d324-4ae8-b115-2cfd95a8fa98   \n",
              "2  9084e5f1-75f5-4f15-aa3d-0676073b4aaf   \n",
              "3  7d36a275-f3a3-44ea-8cbc-caa0d67749c4   \n",
              "4  42ba634c-b7ce-491a-91c0-e2b1424af827   \n",
              "5  47000f09-22ab-4309-9411-c0c738327c25   \n",
              "6  927ce408-c559-4f17-b673-37b0e9e301d7   \n",
              "7  8eaf98bd-e728-4d9b-8d4b-013a8c66a173   \n",
              "8  11f67276-4330-4c68-83ad-2599ec9711b2   \n",
              "9  4800cdcb-c5b0-4055-b3c8-a71dd23d8a6e   \n",
              "\n",
              "                                               title  \\\n",
              "0                  2025: The Year Of Alphabet (GOOG)   \n",
              "1  Why I'm Doubling Down On My Adobe Position (NA...   \n",
              "2  Global week ahead: The start of a Santa Rally ...   \n",
              "3       Global Risk Monitor: Week in Review – Nov 28   \n",
              "4  Mcap boost: 7 of top-10 firms gain ₹96,201 cr;...   \n",
              "5  QQQX: Tax-Efficient Dividends From The Nasdaq-...   \n",
              "6  Wall Street predicts rebound in Indian markets...   \n",
              "7  Dow Stock: Approaching A Bottom But Recovery W...   \n",
              "8  Montrose Environmental Stock Looks Good Despit...   \n",
              "9  The Deal With Meta, Google Stock’s AI Chips To...   \n",
              "\n",
              "                                         description  \\\n",
              "0  No stock has seen a bigger jump recently than ...   \n",
              "1  Adobe's revenue is highly predictable, driven ...   \n",
              "2                                                NaN   \n",
              "3  KEY ISSUES Silver surged 13% for the week and ...   \n",
              "4  Market valuations of seven top firms rose by ₹...   \n",
              "5  Discover why Nuveen NASDAQ 100 Dynamic Overwri...   \n",
              "6  Wall Street giants anticipate a rebound for In...   \n",
              "7  Dow faces weak demand and excess capacity, but...   \n",
              "8  Discover why Montrose Environmental Group (MEG...   \n",
              "9  Discover why Alphabet is rated a Strong Buy as...   \n",
              "\n",
              "                                            keywords  \\\n",
              "0                                                NaN   \n",
              "1                                                NaN   \n",
              "2                           STOXX 600, business news   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "5                                                NaN   \n",
              "6  Indian markets rebound, Morgan Stanley India f...   \n",
              "7                                                NaN   \n",
              "8                                                NaN   \n",
              "9                                                NaN   \n",
              "\n",
              "                                             snippet  \\\n",
              "0  vzphotos/iStock Editorial via Getty Images\\n\\n...   \n",
              "1  To say that Adobe ( ADBE ) stock has not had a...   \n",
              "2  And just like that... December is upon us. It'...   \n",
              "3  KEY ISSUES\\n\\nSilver surged 13% for the week a...   \n",
              "4  The combined market valuation of seven of the ...   \n",
              "5  With the rise of covered call ETFs, it can be ...   \n",
              "6  Live Events\\n\\nBloomberg\\n\\nBloomberg\\n\\nRBI S...   \n",
              "7  Shares of Dow have been a very poor performer ...   \n",
              "8  Robert F. Abbott has been investing his family...   \n",
              "9  Alphabet Inc. ( GOOG ) ( GOOGL ) is on a fanta...   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://seekingalpha.com/article/4848680-2025-...   \n",
              "1  https://seekingalpha.com/article/4848762-why-i...   \n",
              "2  https://www.cnbc.com/2025/11/30/global-week-ah...   \n",
              "3  https://global-macro-monitor.com/2025/11/29/gl...   \n",
              "4  https://www.thehindubusinessline.com/markets/m...   \n",
              "5  https://seekingalpha.com/article/4848757-qqqx-...   \n",
              "6  https://economictimes.indiatimes.com/markets/s...   \n",
              "7  https://seekingalpha.com/article/4848756-dow-a...   \n",
              "8  https://seekingalpha.com/article/4848754-montr...   \n",
              "9  https://seekingalpha.com/article/4848753-the-d...   \n",
              "\n",
              "                                           image_url language  \\\n",
              "0  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "1  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "2  https://image.cnbcfm.com/api/v1/image/10823257...       en   \n",
              "3  https://global-macro-monitor.com/wp-content/up...       en   \n",
              "4  https://bl-i.thgim.com/public/incoming/ji6cih/...       en   \n",
              "5  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "6  https://img.etimg.com/thumb/msid-125668199,wid...       en   \n",
              "7  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "8  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "9  https://static.seekingalpha.com/cdn/s3/uploads...       en   \n",
              "\n",
              "                  published_at                        source  relevance_score  \\\n",
              "0  2025-11-30T05:30:00.000000Z              seekingalpha.com              NaN   \n",
              "1  2025-11-30T05:25:01.000000Z              seekingalpha.com              NaN   \n",
              "2  2025-11-30T05:10:58.000000Z                      cnbc.com              NaN   \n",
              "3  2025-11-30T05:07:50.000000Z      global-macro-monitor.com              NaN   \n",
              "4  2025-11-30T05:04:20.000000Z      thehindubusinessline.com              NaN   \n",
              "5  2025-11-30T04:23:00.000000Z              seekingalpha.com              NaN   \n",
              "6  2025-11-30T04:14:43.000000Z  economictimes.indiatimes.com              NaN   \n",
              "7  2025-11-30T04:08:00.000000Z              seekingalpha.com              NaN   \n",
              "8  2025-11-30T03:38:00.000000Z              seekingalpha.com              NaN   \n",
              "9  2025-11-30T03:23:00.000000Z              seekingalpha.com              NaN   \n",
              "\n",
              "                                            entities  \\\n",
              "0  [{'symbol': 'GOOGL', 'name': 'Alphabet Inc.', ...   \n",
              "1  [{'symbol': 'ADBE', 'name': 'Adobe Inc.', 'exc...   \n",
              "2  [{'symbol': 'M', 'name': \"Macy's, Inc.\", 'exch...   \n",
              "3  [{'symbol': 'NVDA', 'name': 'NVIDIA Corporatio...   \n",
              "4  [{'symbol': 'SBKFF', 'name': 'State Bank of In...   \n",
              "5  [{'symbol': 'QQQX', 'name': 'Nuveen Nasdaq 100...   \n",
              "6  [{'symbol': 'C', 'name': 'Citigroup Inc.', 'ex...   \n",
              "7  [{'symbol': 'DOW', 'name': 'Dow Inc.', 'exchan...   \n",
              "8  [{'symbol': 'MEG', 'name': 'Montrose Environme...   \n",
              "9  [{'symbol': 'GOOG', 'name': 'Alphabet Inc.', '...   \n",
              "\n",
              "                                             similar  sentiment  \\\n",
              "0                                                 []    0.00000   \n",
              "1                                                 []    0.00000   \n",
              "2                                                 []    0.69080   \n",
              "3                                                 []   -0.36120   \n",
              "4                                                 []    0.00000   \n",
              "5                                                 []    0.37150   \n",
              "6  [{'uuid': 'd359704e-cc4f-4e18-a564-f8e189eae75...   -0.63690   \n",
              "7  [{'uuid': 'c8cdbd28-1e3c-45f5-9333-66b6b389aee...    0.00000   \n",
              "8                                                 []    0.49770   \n",
              "9                                                 []    0.61495   \n",
              "\n",
              "                                                text  length  \\\n",
              "0  vzphotos/iStock Editorial via Getty Images\\n\\n...      42   \n",
              "1  Why I'm Doubling Down On My Adobe Position (NA...       1   \n",
              "2  And just like that... December is upon us. It'...     493   \n",
              "3  KEY ISSUES\\n\\nSilver surged 13% for the week a...     729   \n",
              "4  The combined market valuation of seven of the ...     254   \n",
              "5  QQQX: Tax-Efficient Dividends From The Nasdaq-...       1   \n",
              "6  It seems like you're already an ETPrime member...      41   \n",
              "7  Dow Stock: Approaching A Bottom But Recovery W...       1   \n",
              "8  Montrose Environmental Stock Looks Good Despit...       1   \n",
              "9  The Deal With Meta, Google Stock’s AI Chips To...       1   \n",
              "\n",
              "                                          clean_text  \n",
              "0  vzphotos istock editorial via getty images sin...  \n",
              "1  doubling adobe position nasdaq adbe adobe reve...  \n",
              "2  like december upon us volatile handover novemb...  \n",
              "3  key issues silver surged 13 week 90 year date ...  \n",
              "4  combined market valuation seven top 10 valued ...  \n",
              "5  qqqx tax efficient dividends nasdaq 100 nasdaq...  \n",
              "6  seems like already etprime member login using ...  \n",
              "7  dow stock approaching bottom recovery gradual ...  \n",
              "8  montrose environmental stock looks good despit...  \n",
              "9  deal meta google stock ai chips power new cycl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c41ba14-4b1b-4506-9270-19e484fcff8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>keywords</th>\n",
              "      <th>snippet</th>\n",
              "      <th>url</th>\n",
              "      <th>image_url</th>\n",
              "      <th>language</th>\n",
              "      <th>published_at</th>\n",
              "      <th>source</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>entities</th>\n",
              "      <th>similar</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>487e6a88-d3c2-4ae1-8dc2-26af6b31d688</td>\n",
              "      <td>2025: The Year Of Alphabet (GOOG)</td>\n",
              "      <td>No stock has seen a bigger jump recently than ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vzphotos/iStock Editorial via Getty Images\\n\\n...</td>\n",
              "      <td>https://seekingalpha.com/article/4848680-2025-...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:30:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'GOOGL', 'name': 'Alphabet Inc.', ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>vzphotos/iStock Editorial via Getty Images\\n\\n...</td>\n",
              "      <td>42</td>\n",
              "      <td>vzphotos istock editorial via getty images sin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92b5c2bd-d324-4ae8-b115-2cfd95a8fa98</td>\n",
              "      <td>Why I'm Doubling Down On My Adobe Position (NA...</td>\n",
              "      <td>Adobe's revenue is highly predictable, driven ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To say that Adobe ( ADBE ) stock has not had a...</td>\n",
              "      <td>https://seekingalpha.com/article/4848762-why-i...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:25:01.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'ADBE', 'name': 'Adobe Inc.', 'exc...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Why I'm Doubling Down On My Adobe Position (NA...</td>\n",
              "      <td>1</td>\n",
              "      <td>doubling adobe position nasdaq adbe adobe reve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9084e5f1-75f5-4f15-aa3d-0676073b4aaf</td>\n",
              "      <td>Global week ahead: The start of a Santa Rally ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>STOXX 600, business news</td>\n",
              "      <td>And just like that... December is upon us. It'...</td>\n",
              "      <td>https://www.cnbc.com/2025/11/30/global-week-ah...</td>\n",
              "      <td>https://image.cnbcfm.com/api/v1/image/10823257...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:10:58.000000Z</td>\n",
              "      <td>cnbc.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'M', 'name': \"Macy's, Inc.\", 'exch...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.69080</td>\n",
              "      <td>And just like that... December is upon us. It'...</td>\n",
              "      <td>493</td>\n",
              "      <td>like december upon us volatile handover novemb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7d36a275-f3a3-44ea-8cbc-caa0d67749c4</td>\n",
              "      <td>Global Risk Monitor: Week in Review – Nov 28</td>\n",
              "      <td>KEY ISSUES Silver surged 13% for the week and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KEY ISSUES\\n\\nSilver surged 13% for the week a...</td>\n",
              "      <td>https://global-macro-monitor.com/2025/11/29/gl...</td>\n",
              "      <td>https://global-macro-monitor.com/wp-content/up...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:07:50.000000Z</td>\n",
              "      <td>global-macro-monitor.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'NVDA', 'name': 'NVIDIA Corporatio...</td>\n",
              "      <td>[]</td>\n",
              "      <td>-0.36120</td>\n",
              "      <td>KEY ISSUES\\n\\nSilver surged 13% for the week a...</td>\n",
              "      <td>729</td>\n",
              "      <td>key issues silver surged 13 week 90 year date ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42ba634c-b7ce-491a-91c0-e2b1424af827</td>\n",
              "      <td>Mcap boost: 7 of top-10 firms gain ₹96,201 cr;...</td>\n",
              "      <td>Market valuations of seven top firms rose by ₹...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The combined market valuation of seven of the ...</td>\n",
              "      <td>https://www.thehindubusinessline.com/markets/m...</td>\n",
              "      <td>https://bl-i.thgim.com/public/incoming/ji6cih/...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T05:04:20.000000Z</td>\n",
              "      <td>thehindubusinessline.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'SBKFF', 'name': 'State Bank of In...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>The combined market valuation of seven of the ...</td>\n",
              "      <td>254</td>\n",
              "      <td>combined market valuation seven top 10 valued ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>47000f09-22ab-4309-9411-c0c738327c25</td>\n",
              "      <td>QQQX: Tax-Efficient Dividends From The Nasdaq-...</td>\n",
              "      <td>Discover why Nuveen NASDAQ 100 Dynamic Overwri...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>With the rise of covered call ETFs, it can be ...</td>\n",
              "      <td>https://seekingalpha.com/article/4848757-qqqx-...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:23:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'QQQX', 'name': 'Nuveen Nasdaq 100...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.37150</td>\n",
              "      <td>QQQX: Tax-Efficient Dividends From The Nasdaq-...</td>\n",
              "      <td>1</td>\n",
              "      <td>qqqx tax efficient dividends nasdaq 100 nasdaq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>927ce408-c559-4f17-b673-37b0e9e301d7</td>\n",
              "      <td>Wall Street predicts rebound in Indian markets...</td>\n",
              "      <td>Wall Street giants anticipate a rebound for In...</td>\n",
              "      <td>Indian markets rebound, Morgan Stanley India f...</td>\n",
              "      <td>Live Events\\n\\nBloomberg\\n\\nBloomberg\\n\\nRBI S...</td>\n",
              "      <td>https://economictimes.indiatimes.com/markets/s...</td>\n",
              "      <td>https://img.etimg.com/thumb/msid-125668199,wid...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:14:43.000000Z</td>\n",
              "      <td>economictimes.indiatimes.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'C', 'name': 'Citigroup Inc.', 'ex...</td>\n",
              "      <td>[{'uuid': 'd359704e-cc4f-4e18-a564-f8e189eae75...</td>\n",
              "      <td>-0.63690</td>\n",
              "      <td>It seems like you're already an ETPrime member...</td>\n",
              "      <td>41</td>\n",
              "      <td>seems like already etprime member login using ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8eaf98bd-e728-4d9b-8d4b-013a8c66a173</td>\n",
              "      <td>Dow Stock: Approaching A Bottom But Recovery W...</td>\n",
              "      <td>Dow faces weak demand and excess capacity, but...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Shares of Dow have been a very poor performer ...</td>\n",
              "      <td>https://seekingalpha.com/article/4848756-dow-a...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T04:08:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'DOW', 'name': 'Dow Inc.', 'exchan...</td>\n",
              "      <td>[{'uuid': 'c8cdbd28-1e3c-45f5-9333-66b6b389aee...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>Dow Stock: Approaching A Bottom But Recovery W...</td>\n",
              "      <td>1</td>\n",
              "      <td>dow stock approaching bottom recovery gradual ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11f67276-4330-4c68-83ad-2599ec9711b2</td>\n",
              "      <td>Montrose Environmental Stock Looks Good Despit...</td>\n",
              "      <td>Discover why Montrose Environmental Group (MEG...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Robert F. Abbott has been investing his family...</td>\n",
              "      <td>https://seekingalpha.com/article/4848754-montr...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T03:38:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'MEG', 'name': 'Montrose Environme...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.49770</td>\n",
              "      <td>Montrose Environmental Stock Looks Good Despit...</td>\n",
              "      <td>1</td>\n",
              "      <td>montrose environmental stock looks good despit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4800cdcb-c5b0-4055-b3c8-a71dd23d8a6e</td>\n",
              "      <td>The Deal With Meta, Google Stock’s AI Chips To...</td>\n",
              "      <td>Discover why Alphabet is rated a Strong Buy as...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alphabet Inc. ( GOOG ) ( GOOGL ) is on a fanta...</td>\n",
              "      <td>https://seekingalpha.com/article/4848753-the-d...</td>\n",
              "      <td>https://static.seekingalpha.com/cdn/s3/uploads...</td>\n",
              "      <td>en</td>\n",
              "      <td>2025-11-30T03:23:00.000000Z</td>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'symbol': 'GOOG', 'name': 'Alphabet Inc.', '...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.61495</td>\n",
              "      <td>The Deal With Meta, Google Stock’s AI Chips To...</td>\n",
              "      <td>1</td>\n",
              "      <td>deal meta google stock ai chips power new cycl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c41ba14-4b1b-4506-9270-19e484fcff8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c41ba14-4b1b-4506-9270-19e484fcff8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c41ba14-4b1b-4506-9270-19e484fcff8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4f1e5d2c-4001-4f70-a58b-0305b692450e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f1e5d2c-4001-4f70-a58b-0305b692450e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4f1e5d2c-4001-4f70-a58b-0305b692450e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news_data",
              "summary": "{\n  \"name\": \"news_data\",\n  \"rows\": 9067,\n  \"fields\": [\n    {\n      \"column\": \"uuid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9057,\n        \"samples\": [\n          \"895f7a63-0fe8-431d-994d-b905a848bf7d\",\n          \"7458c578-eb7c-496d-b5c6-ad8cb0b9a10e\",\n          \"652e6d5a-3227-4cf6-8568-4c0e0818e497\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8881,\n        \"samples\": [\n          \"Union Pacific profits rise on operational efficiency, pricing gains\",\n          \"How Is Morgan Stanley's Stock Performance Compared to Other Capital Market Stocks\",\n          \"Intel Corporation (INTC) is Attracting Investor Attention: Here is What You Should Know\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8387,\n        \"samples\": [\n          \"Amazon's\\u00a0You buy. We donate.\\u00a0campaign is returning to help tackle hygiene poverty in the UK.\",\n          \"VANCOUVER, British Columbia, Oct. 30, 2025 (GLOBE NEWSWIRE) -- Xali Gold Corp. (TSXV:XGC) ('Xali Gold\\u201d or the 'Company\\u201d) announces that certain directors, officers, employees and consultants of the Company have been granted incentive stock options to purchase 2,200,000 common shares of Xali Gold at an exercise price equal to $0.05 per share. The options have a 5-year term, expiring October 30, 2030.\",\n          \"2025-10-28. The following slide deck was published by MSCI Inc.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3229,\n        \"samples\": [\n          \"Tidewater Inc., offshore support vessels, offshore energy industry, Tidewater, revenue guidance, marine support, marine service\",\n          \"KLN, Named, Exclusive, Distributor, for, Siemens, Healthineers\",\n          \"Larsen & Toubro, General Atomics, unmanned aircraft, MALE drones, defence ecosystem, defence manufacturing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snippet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6433,\n        \"samples\": [\n          \"Trading houses, hedge funds and banks are on a hiring spree for specialist gold traders as interest in the metal soars, creating a battle for talent that is dri...\",\n          \"Galeanu Mihai/iStock via Getty Images\\n\\nDear Partners,\\n\\nI am pleased to report that Alluvial Fund produced a return of 15.5% in the third quarter, bringing our 2...\",\n          \"Net Profit Surges 45.4% YoY in 3Q 2025\\n\\nHONG KONG, SHANGHAI, Oct. 28, 2025 /PRNewswire/ -- Ping An Insurance (Group) Company of China, Ltd. (hereafter \\\"Ping An\\\"...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9057,\n        \"samples\": [\n          \"https://www.manilatimes.net/2025/10/27/tmt-newswire/globenewswire/neumora-therapeutics-announces-initiation-of-phase-1-clinical-study-of-m4-positive-allosteric-modulator-nmra-898/2208967\",\n          \"https://finance.yahoo.com/news/ubs-lowers-airbnb-abnb-pt-133046220.html\",\n          \"https://seekingalpha.com/article/4833093-eastern-bankshares-inc-2025-q3-results-earnings-call-presentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5782,\n        \"samples\": [\n          \"https://static.seekingalpha.com/cdn/s3/uploads/getty_images/1418324628/image_1418324628.jpg?io=getty-c-w630\",\n          \"https://staticx-tuner.zacks.com/images/default_article_images/default269.jpg\",\n          \"https://argaamplus.s3.amazonaws.com/53404d14-48b9-4750-ba69-93d386c1ecc9.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"published_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8562,\n        \"samples\": [\n          \"2025-10-27T10:36:42.000000Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 180,\n        \"samples\": [\n          \"businessinsider.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9042,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similar\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1548,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30891443478745234,\n        \"min\": -0.9042,\n        \"max\": 0.9858,\n        \"num_unique_values\": 3327,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7883,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 789,\n        \"min\": 1,\n        \"max\": 12606,\n        \"num_unique_values\": 1315,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7879,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "news_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9cd4177",
      "metadata": {
        "id": "b9cd4177"
      },
      "source": [
        "## Clean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61098227",
      "metadata": {
        "id": "61098227"
      },
      "source": [
        "### Check for Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "960758c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "960758c2",
        "outputId": "d7decd8f-d54e-495c-c9d9-ff3f94a2033b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Number_Missing  Missing_Percentage\n",
            "uuid                          0            0.000000\n",
            "title                         0            0.000000\n",
            "description                 414            4.566009\n",
            "keywords                   4774           52.652476\n",
            "snippet                      37            0.408073\n",
            "url                           0            0.000000\n",
            "image_url                    36            0.397044\n",
            "language                      0            0.000000\n",
            "published_at                  0            0.000000\n",
            "source                        0            0.000000\n",
            "relevance_score            9067          100.000000\n",
            "entities                      0            0.000000\n",
            "similar                       0            0.000000\n",
            "sentiment                     0            0.000000\n",
            "text                          0            0.000000\n",
            "length                        0            0.000000\n",
            "clean_text                    0            0.000000\n"
          ]
        }
      ],
      "source": [
        "is_na = pd.DataFrame(news_data.isna().sum())\n",
        "is_na.columns = [\"Number_Missing\"]\n",
        "is_na[\"Missing_Percentage\"] = (is_na[\"Number_Missing\"] / len(news_data) * 100)\n",
        "print(is_na)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f1c8b6",
      "metadata": {
        "id": "56f1c8b6"
      },
      "source": [
        "### Check for Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1402a818",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1402a818",
        "outputId": "615eb8ce-617e-474a-9645-520937f21c0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "news_data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bff61d1",
      "metadata": {
        "id": "0bff61d1"
      },
      "source": [
        "## Split the Data to Train, Test, and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "01d36764",
      "metadata": {
        "id": "01d36764"
      },
      "outputs": [],
      "source": [
        "test_size = 0.20\n",
        "val_size = 0.10\n",
        "\n",
        "# Splitting the data into train and temp (which will be further split into validation and test)\n",
        "train_df, test_df = train_test_split(news_data, test_size=test_size, random_state=SEED)\n",
        "\n",
        "# Splitting train into validation and test sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=val_size, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff104da1",
      "metadata": {
        "id": "ff104da1"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78b88cc",
      "metadata": {
        "id": "c78b88cc"
      },
      "source": [
        "### Word Tokenization\n",
        "\n",
        "the words in the sentence would be tokenized since gensim's fasttext model requires the sentence to be tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "43969a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43969a98",
        "outputId": "a0b7fcb2-424c-4596-b494-b74ee5640e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing Train Data...: 100%|██████████| 6527/6527 [00:30<00:00, 214.22news/s]\n",
            "Preprocessing Test Data...: 100%|██████████| 1814/1814 [00:08<00:00, 210.00news/s]\n",
            "Preprocessing Validation Data...: 100%|██████████| 726/726 [00:03<00:00, 236.65news/s]\n"
          ]
        }
      ],
      "source": [
        "# tqdm for cleaner output\n",
        "tqdm.pandas(desc=\"Preprocessing Train Data...\", unit=\"news\")\n",
        "train_df[\"tokenized_text\"] = train_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Preprocessing Test Data...\", unit=\"news\")\n",
        "test_df[\"tokenized_text\"] = test_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Preprocessing Validation Data...\", unit=\"news\")\n",
        "val_df[\"tokenized_text\"] = val_df[\"clean_text\"].progress_apply(\n",
        "                                                    lambda x: clean_text(\n",
        "                                                        text = x,\n",
        "                                                        tokenize = True,\n",
        "                                                        remove_stop_words = True,\n",
        "                                                        stem_words = True,\n",
        "                                                        remove_url = True,\n",
        "                                                        remove_emojis = \"keep\"\n",
        "                                                        )\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d436c5c1",
      "metadata": {
        "id": "d436c5c1"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8b1a58",
      "metadata": {
        "id": "7e8b1a58"
      },
      "source": [
        "### Train FastText Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "554eeece",
      "metadata": {
        "id": "554eeece"
      },
      "outputs": [],
      "source": [
        "ft_model = FastText(\n",
        "    sentences=train_df[\"tokenized_text\"],\n",
        "    vector_size=300,    # size of embedding\n",
        "    window=5,           # Window size\n",
        "    min_count=0,        # Since currently there is a low amount of data and some financial\n",
        "                        # terms doesent appear frequentlywe would set this to 0\n",
        "    sg=1,               # skip-gram since some of the financial terms are rare\n",
        "    min_n=3,            # generate all n-grams (e.g. Hello -> \"hel\", \"ell\", \"llo\") so fasttext can understand typos\n",
        "    max_n=8,            # max n-grams\n",
        "    seed=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea353aa",
      "metadata": {
        "id": "aea353aa"
      },
      "source": [
        "### Apply FastText to the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5184a23d",
      "metadata": {
        "id": "5184a23d"
      },
      "outputs": [],
      "source": [
        "# sentence vector function\n",
        "\n",
        "def get_vectors(tokens: list[str]):\n",
        "    return [ft_model.wv.get_vector(word) for word in tokens if word in ft_model.wv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "847b6c45",
      "metadata": {
        "id": "847b6c45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8ea3d2-d885-47c1-e65d-f119e0c16b29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Vectorizing Train Data...: 100%|██████████| 6527/6527 [00:01<00:00, 3825.89news/s]\n",
            "Vectorizing Test Data...: 100%|██████████| 1814/1814 [00:00<00:00, 2289.33news/s]\n",
            "Vectorizing Validation Data...: 100%|██████████| 726/726 [00:00<00:00, 2431.42news/s]\n"
          ]
        }
      ],
      "source": [
        "# tqdm for cleaner output\n",
        "tqdm.pandas(desc=\"Vectorizing Train Data...\", unit=\"news\")\n",
        "train_df[\"vectorized_text\"] = train_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Vectorizing Test Data...\", unit=\"news\")\n",
        "test_df[\"vectorized_text\"] = test_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )\n",
        "\n",
        "tqdm.pandas(desc=\"Vectorizing Validation Data...\", unit=\"news\")\n",
        "val_df[\"vectorized_text\"] = val_df[\"tokenized_text\"].progress_apply(\n",
        "                                                    lambda x: get_vectors(\n",
        "                                                        tokens = x\n",
        "                                                        )\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c554397",
      "metadata": {
        "id": "1c554397"
      },
      "source": [
        "## Split the X and Y values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0e5912bc",
      "metadata": {
        "id": "0e5912bc"
      },
      "outputs": [],
      "source": [
        "x_train = train_df[\"vectorized_text\"]\n",
        "x_test = test_df[\"vectorized_text\"]\n",
        "x_val = val_df[\"vectorized_text\"]\n",
        "\n",
        "y_train = train_df[\"sentiment\"].to_numpy()\n",
        "y_test = test_df[\"sentiment\"].to_numpy()\n",
        "y_val = val_df[\"sentiment\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fe356e02",
      "metadata": {
        "id": "fe356e02"
      },
      "outputs": [],
      "source": [
        "# # get sample because run on laptop\n",
        "# x_train_sample = x_train[:64]\n",
        "# x_test_sample = x_test[:64]\n",
        "# x_val_sample = x_val[:64]\n",
        "\n",
        "# y_train_sample = y_train[:64]\n",
        "# y_test_sample = y_test[:64]\n",
        "# y_val_sample = y_val[:64]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ac814e",
      "metadata": {
        "id": "62ac814e"
      },
      "source": [
        "## Apply Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5d1f92b6",
      "metadata": {
        "id": "5d1f92b6"
      },
      "outputs": [],
      "source": [
        "# Padding Function\n",
        "def pad_sequences(vectorized_sentences, max_len=300):\n",
        "    padded_list = []\n",
        "\n",
        "    for vec in vectorized_sentences:\n",
        "        vec = torch.tensor(vec, dtype=torch.float32)\n",
        "\n",
        "        # Truncate if too long\n",
        "        if vec.shape[0] > max_len:\n",
        "            vec = vec[:max_len]\n",
        "\n",
        "        # Pad if too short\n",
        "        if vec.shape[0] < max_len:\n",
        "            pad_length = max_len - vec.shape[0]\n",
        "            padding = torch.zeros((pad_length, vec.shape[1]))  # (pad_len, embedding_dim)\n",
        "            vec = torch.cat([vec, padding], dim=0)  # post-padding\n",
        "\n",
        "        padded_list.append(vec)\n",
        "\n",
        "    return torch.stack(padded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b9db4712",
      "metadata": {
        "id": "b9db4712",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8435b7d-daf6-43be-a4cb-969295faf045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2428613510.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  vec = torch.tensor(vec, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "max_padding_len = 300\n",
        "\n",
        "x_train_vectors = x_train.tolist()\n",
        "x_train_padded = pad_sequences(x_train_vectors, max_len = max_padding_len)\n",
        "x_train_padded = x_train_padded.numpy()\n",
        "\n",
        "x_test_vectors = x_test.tolist()\n",
        "x_test_padded = pad_sequences(x_test_vectors, max_len = max_padding_len)\n",
        "x_test_padded = x_test_padded.numpy()\n",
        "\n",
        "x_val_vectors = x_val.tolist()\n",
        "x_val_padded = pad_sequences(x_val_vectors, max_len = max_padding_len)\n",
        "x_val_padded = x_val_padded.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca3a5a3",
      "metadata": {
        "id": "eca3a5a3"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "af6601a6",
      "metadata": {
        "id": "af6601a6"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Train data\n",
        "x_train_tensor = torch.tensor(x_train_padded, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# test data\n",
        "x_test_tensor = torch.tensor(x_test_padded, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# val data\n",
        "x_val_tensor = torch.tensor(x_val_padded, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b5828b",
      "metadata": {
        "id": "79b5828b"
      },
      "source": [
        "## Build LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0107a86",
      "metadata": {
        "id": "c0107a86"
      },
      "source": [
        "### Model Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a98097dc",
      "metadata": {
        "id": "a98097dc"
      },
      "outputs": [],
      "source": [
        "def define_model(trial, input_size, n_output):\n",
        "    class GridLSTM(nn.Module):\n",
        "        def __init__(self, trial, input_size: int, hidden_size: int, num_layers: int, n_output: int):\n",
        "            super().__init__()\n",
        "\n",
        "            def dense_layer_builder(layer_prefix):\n",
        "                nonlocal input_size, dense_layers\n",
        "\n",
        "                # Dense layer parameters\n",
        "                out_size = trial.suggest_int(f\"{layer_prefix}_output_size\", 32, 512)\n",
        "                dense_layers.append(nn.Linear(input_size, out_size))\n",
        "\n",
        "                # Add drop out rate so that it reduces overfitting and improve generlization\n",
        "                dropout_rate = trial.suggest_float(f\"{layer_prefix}_dropout_rate\", 0.0, 0.8)\n",
        "                if dropout_rate > 0:\n",
        "                    dense_layers.append(nn.Dropout(dropout_rate)) # Update input size for the next dense layer based on the output size of this one\n",
        "\n",
        "                input_size = out_size\n",
        "\n",
        "            if num_layers >= 3:\n",
        "                lstm_dropout = trial.suggest_float(\"lstm_dropout\", 0.0, 0.8)\n",
        "            else:\n",
        "                lstm_dropout = 0\n",
        "                trial.set_user_attr(\"lstm_dropout\", lstm_dropout)\n",
        "\n",
        "            self.hidden_size = hidden_size\n",
        "            self.num_layers = num_layers\n",
        "\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size = input_size,\n",
        "                hidden_size = hidden_size, #number of LSTM Blocks\n",
        "                num_layers = num_layers, #number of LSTM layers\n",
        "                batch_first = True, # so that pytorch recognizes the input to be [batch_size, sequence_length, input_size] otherwise [sequence_length, batch_size, input_size]\n",
        "                dropout = lstm_dropout\n",
        "            )\n",
        "\n",
        "            # Make the dense layers\n",
        "            dense_layers = []\n",
        "            input_size = hidden_size\n",
        "            n_dense_layers = trial.suggest_int(\"n_dense_layer\", 1, 25)\n",
        "\n",
        "            for i in range(n_dense_layers):\n",
        "                dense_layer_builder(f\"dense_{i}\") #input size would be updated each iteration\n",
        "\n",
        "            #output Layer\n",
        "            dense_layers.append(nn.Linear(input_size, n_output))\n",
        "\n",
        "            # Register dense layers as nn.Sequential\n",
        "            self.dense = nn.Sequential(*dense_layers)\n",
        "\n",
        "        def forward(self, input_tensor): # Forward pass\n",
        "            if input_tensor.dim() == 2:  # [seq_len, input_size] unbatched\n",
        "                input_tensor = input_tensor.unsqueeze(1)  # make [1, seq_len, input_size] if the dimensions\n",
        "                batch_size = input_tensor.size(0)\n",
        "                h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "                c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            else:  # [batch_size, seq_len, input_size]\n",
        "                batch_size = input_tensor.size(0)\n",
        "                h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "                c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            out, _ = self.lstm(input_tensor, (h0, c0))  # LSTM forward\n",
        "            out = self.dense(out[:, -1, :])             # Take last time step and pass through dense\n",
        "            return out\n",
        "\n",
        "    hidden_size = trial.suggest_int(\"lstm_hidden_size\", 8, 512)\n",
        "    num_layers = trial.suggest_int(\"lstm_num_layers\", 1, 6)\n",
        "    return GridLSTM(trial, input_size, hidden_size, num_layers, n_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da715301",
      "metadata": {
        "id": "da715301"
      },
      "source": [
        "### Optuna Objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "69054d08",
      "metadata": {
        "id": "69054d08"
      },
      "outputs": [],
      "source": [
        "def objective(trial, n_input, n_output, train_loader, val_loader, epochs, device):\n",
        "    # Reset the seed for each trial of the gridsearch\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    # Parameters for early stopping\n",
        "    best_mse = inf # Inital MSE score\n",
        "    patience = 3 # number of epochs to wait without improvement before stopping\n",
        "    epochs_no_improve = 0 # Epochs counter without improvement\n",
        "    best_model_state = None # To store the best model weights\n",
        "\n",
        "    # Model Initialization\n",
        "    model = define_model(trial, n_input, n_output).to(device)\n",
        "\n",
        "    # Learning rate\n",
        "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)  # log-scale search\n",
        "\n",
        "    # Optimizer Set-Up\n",
        "    optimizer_name = trial.suggest_categorical(\"Optimizer\", [\"Adam\", \"Momentum\", \"AdamW\"])\n",
        "    optimizer = {\n",
        "        \"Adam\": optim.Adam(model.parameters(), lr=lr),\n",
        "        \"Momentum\": optim.SGD(model.parameters(),\n",
        "                            lr=lr,\n",
        "                            momentum=trial.suggest_float(\"sgd_momentum\", 1e-5, 1, log=True)),\n",
        "        \"AdamW\": optim.AdamW(model.parameters(),\n",
        "                            lr=lr,\n",
        "                            weight_decay=trial.suggest_float(\"adamw_weight_decay\", 1e-5, 1, log=True))\n",
        "    }[optimizer_name]\n",
        "\n",
        "    # Loss function\n",
        "    loss_function = nn.MSELoss() # This is to punish the model for large errors\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs = inputs.to(device).float()\n",
        "            targets = targets.to(device).float()\n",
        "\n",
        "            # Check if the data contains NaN values\n",
        "            if not torch.isfinite(inputs).all() or not torch.isfinite(targets).all():\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = loss_function(outputs.view(-1), targets.view(-1))\n",
        "\n",
        "            # Check if the Loss outputs infinite values due to exploding or vanishing gradient\n",
        "            if not torch.isfinite(loss):\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Early Stopping Check\n",
        "        # Validation (after training loop finishes)\n",
        "        model.eval() # Make model in evaluation mode\n",
        "        all_preds = [] # For the model predictions and true lables\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad(): # Turns off gradient tracking for speeding up validation, saves memory, lock memory weights\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device).float(), labels.to(device).float() # move lables to the device\n",
        "                outputs = model(inputs) # Pass input data to the model to get raw logits\n",
        "\n",
        "                all_preds.extend(outputs.squeeze().cpu().numpy()) # move the predictions and lables to the cpu since numpy only works on CPU memory. then convert to numpy arrays then append to the list.\n",
        "                all_labels.extend(labels.squeeze().cpu().numpy())\n",
        "\n",
        "        # Calculate MSE Score\n",
        "        curr_mse = mean_squared_error(all_labels, all_preds) # Calculate mse score\n",
        "\n",
        "        # Check if the emtric outputs infinite or NaN values\n",
        "        if not np.isfinite(curr_mse):\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        if curr_mse < best_mse:\n",
        "            best_mse = curr_mse\n",
        "            epochs_no_improve = 0\n",
        "            best_model_state = deepcopy(model.state_dict()) # Save the model state\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                tqdm.write(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    # Load best model weights for reporting\n",
        "    model.load_state_dict(best_model_state)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad(): # Turns off gradient tracking for speeding up validation, saves memory, lock memory weights\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move lables to the device\n",
        "            outputs = model(inputs) # Pass input data to the model to get raw logits\n",
        "\n",
        "            all_preds.extend(outputs.squeeze().cpu().numpy()) # move the predictions and lables to the cpu since numpy only works on CPU memory. then convert to numpy arrays then append to the list.\n",
        "            all_labels.extend(labels.squeeze().cpu().numpy())\n",
        "\n",
        "    best_mse = mean_squared_error(all_labels, all_preds)\n",
        "    tqdm.write(f\"Trial {trial.number}: Best MSE Score = {best_mse:.4f}\")\n",
        "    trial.set_user_attr(\"best_model_state\", best_model_state)\n",
        "    return best_mse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eae52f0",
      "metadata": {
        "id": "2eae52f0"
      },
      "source": [
        "### Initialte Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b999b0",
      "metadata": {
        "id": "98b999b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb3de0d-b104-4d33-85c1-19a58188b2c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Trial:   0%|                                          | 0/100 [1:46:47<?, ?it/s]\n",
            "Gridsearch ...:  72%|███████▏  | 72/100 [1:46:47<35:54, 76.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Trial:   0%|                                          | 0/100 [1:46:47<?, ?it/s]\n",
            "Gridsearch ...:  72%|███████▏  | 72/100 [1:46:47<35:54, 76.94s/it]\u001b[A[I 2025-12-24 03:48:33,235] Trial 72 finished with value: 0.09327636243180062 and parameters: {'lstm_hidden_size': 479, 'lstm_num_layers': 1, 'n_dense_layer': 14, 'dense_0_output_size': 90, 'dense_0_dropout_rate': 0.6407003455903444, 'dense_1_output_size': 38, 'dense_1_dropout_rate': 0.6089731941719279, 'dense_2_output_size': 45, 'dense_2_dropout_rate': 0.35178344869349204, 'dense_3_output_size': 241, 'dense_3_dropout_rate': 0.024714580234059452, 'dense_4_output_size': 435, 'dense_4_dropout_rate': 0.5016533313606342, 'dense_5_output_size': 142, 'dense_5_dropout_rate': 0.06783975062356323, 'dense_6_output_size': 166, 'dense_6_dropout_rate': 0.4118015639995035, 'dense_7_output_size': 210, 'dense_7_dropout_rate': 0.11308511568018864, 'dense_8_output_size': 227, 'dense_8_dropout_rate': 0.5156342896774656, 'dense_9_output_size': 106, 'dense_9_dropout_rate': 0.2091027136573301, 'dense_10_output_size': 436, 'dense_10_dropout_rate': 0.09660382907195914, 'dense_11_output_size': 510, 'dense_11_dropout_rate': 0.23319731064251834, 'dense_12_output_size': 159, 'dense_12_dropout_rate': 0.15956465352926008, 'dense_13_output_size': 495, 'dense_13_dropout_rate': 0.00015568457861370177, 'learning_rate': 1.4353168353770824e-05, 'Optimizer': 'Adam', 'sgd_momentum': 2.1160502685194e-05, 'adamw_weight_decay': 0.2673794109787197}. Best is trial 60 with value: 0.09044564193475986.\n",
            "\n",
            "Gridsearch ...:  73%|███████▎  | 73/100 [1:46:47<28:32, 63.41s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 72: Best MSE Score = 0.0933\n"
          ]
        }
      ],
      "source": [
        "# The input size\n",
        "input_size = x_train_padded.shape[2]\n",
        "\n",
        "# Get number of outputs\n",
        "output_size = 1 # since this is regression there would be only 1 output\n",
        "epochs = 50\n",
        "n_trials = 100\n",
        "\n",
        "samplers = optuna.samplers.TPESampler(n_startup_trials=20) # Bayesian optimization method used by Optuna to sample hyperparameters intelligently (20 random trials first before starting the Bayesian optimization.)\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=samplers) # Minimize MSE score\n",
        "\n",
        "# Tqdm for cleaner output\n",
        "progress_bar = tqdm(total=n_trials, desc=\"Trial\", ncols=80)\n",
        "\n",
        "for _ in tqdm(range(n_trials), desc=\"Gridsearch ...\"):\n",
        "    time.sleep(0.8) #wait for .8 seconds befor clearing the output\n",
        "    clear_output(wait=True) # comment this out of you want to see the whole training process\n",
        "    study.optimize(lambda trial: objective(trial,input_size, output_size, train_loader,\n",
        "                                            val_loader, epochs, device),\n",
        "                    n_trials=1)\n",
        "\n",
        "# Summarize study results\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED]) # get the pruned trials\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE]) # get the succeeded trials\n",
        "\n",
        "print(\"\\nstudy statistics:\")\n",
        "print(f\"  Finished trials: {len(study.trials)}\")\n",
        "print(f\"  Pruned trials:   {len(pruned_trials)}\")\n",
        "print(f\"  Complete trials: {len(complete_trials)}\")\n",
        "\n",
        "# Define model with best params\n",
        "best_trial = study.best_trial\n",
        "print(\"Best trial:\")\n",
        "print(f\"  Best MSE: {best_trial.value:.4f}\")\n",
        "best_model = define_model(best_trial, input_size, output_size).to(device)\n",
        "\n",
        "# Load best weights\n",
        "best_model.load_state_dict(best_trial.user_attrs[\"best_model_state\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d75e65b7",
      "metadata": {
        "id": "d75e65b7"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "874e9ce5",
      "metadata": {
        "id": "874e9ce5"
      },
      "source": [
        "### Model Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e52b5aa",
      "metadata": {
        "id": "0e52b5aa"
      },
      "outputs": [],
      "source": [
        "# Model Builder from Parameters\n",
        "def define_model_from_params(params: dict, input_size: int, n_output: int):\n",
        "    class GridLSTM(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            self.hidden_size = params[\"lstm_hidden_size\"]\n",
        "            self.num_layers = params[\"lstm_num_layers\"]\n",
        "            self.lstm_dropout = params.get(\"lstm_dropout\", 0.0)\n",
        "\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                batch_first=True,\n",
        "                dropout=self.lstm_dropout\n",
        "            )\n",
        "            # Build dense layers\n",
        "            dense_layers = []\n",
        "            dense_input_size = self.lstm.hidden_size\n",
        "            n_dense_layers = params.get(\"n_dense_layer\", 1)\n",
        "\n",
        "            for i in range(n_dense_layers):\n",
        "                out_size = params[f\"dense_{i}_output_size\"]\n",
        "                dense_layers.append(nn.Linear(dense_input_size, out_size))\n",
        "\n",
        "                dropout_rate = params.get(f\"dense_{i}_dropout_rate\", 0.0)\n",
        "                if dropout_rate > 0:\n",
        "                    dense_layers.append(nn.Dropout(dropout_rate))\n",
        "\n",
        "                dense_input_size = out_size\n",
        "\n",
        "            # Output layer\n",
        "            dense_layers.append(nn.Linear(dense_input_size, n_output))\n",
        "            self.dense = nn.Sequential(*dense_layers)\n",
        "\n",
        "        def forward(self, input_tensor):\n",
        "            if input_tensor.dim() == 2:  # [batch_size, input_size]\n",
        "                input_tensor = input_tensor.unsqueeze(1)  # make it [batch_size, seq_len=1, input_size]\n",
        "\n",
        "            batch_size = input_tensor.size(0)\n",
        "\n",
        "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "            # LSTM Forward pass\n",
        "            out, _ = self.lstm(input_tensor, (h0, c0)) # out: [batch_size, seq_len, hidden_size]\n",
        "            out = self.dense(out[:, -1, :]) # take the last time step and pass it to the dense layer\n",
        "            return out\n",
        "\n",
        "    return GridLSTM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273c6bf7",
      "metadata": {
        "id": "273c6bf7"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            all_preds.extend(outputs.view(-1).cpu().numpy())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy())\n",
        "\n",
        "    # Compute metrics\n",
        "    mse = mean_squared_error(all_labels, all_preds)\n",
        "    mae = mean_absolute_error(all_labels, all_preds)\n",
        "    rmse = root_mean_squared_error(all_labels, all_preds)\n",
        "    r2 = r2_score(all_labels, all_preds)\n",
        "\n",
        "    return mse, mae, rmse, r2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9ac2820",
      "metadata": {
        "id": "e9ac2820"
      },
      "source": [
        "### Export and Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e289f630",
      "metadata": {
        "id": "e289f630"
      },
      "outputs": [],
      "source": [
        "model_pytorch_path = os.path.join(project_path,\"models/fast_text_lstm/fast_text_lstm_model.pt\")\n",
        "model_json_path = os.path.join(project_path,\"models/fast_text_lstm/fast_text_lstm_model.json\")\n",
        "seed_path = os.path.join(project_path,\"models/fast_text_lstm/seed.txt\")\n",
        "seed_path = os.path.join(project_path,\"models/word2vec_lstm/seed.txt\")\n",
        "new_model = best_model.to(device)\n",
        "new_model.eval()\n",
        "\n",
        "# Evaluate new model on test set\n",
        "new_mse, new_mae, new_rmse, new_r2 = evaluate_model(\n",
        "                                    new_model,\n",
        "                                    test_loader,\n",
        "                                    device\n",
        "                                    )\n",
        "\n",
        "if os.path.exists(model_pytorch_path) and os.path.exists(model_json_path):\n",
        "    # Load the existing (old) model\n",
        "    with open(model_json_path, \"r\") as f:\n",
        "        best_old_params = json.load(f)\n",
        "\n",
        "    old_model = define_model_from_params(best_old_params, input_size, output_size).to(device)\n",
        "    old_model.load_state_dict(torch.load(model_pytorch_path))\n",
        "    old_model.eval()\n",
        "\n",
        "    # Evaluate the old model\n",
        "    old_mse, old_mae, old_rmse, old_r2 = evaluate_model(\n",
        "                                        old_model,\n",
        "                                        test_loader,\n",
        "                                        device\n",
        "                                        )\n",
        "    print(\"Model Scores:\")\n",
        "    print(f\"Old_mse       = {old_mse:.4f}     | New_mse       = {new_mse:.4f}\")\n",
        "    print(f\"Old_mae       = {old_mae:.4f}     | New_mae       = {new_mae:.4f}\")\n",
        "    print(f\"Old_rmse      = {old_rmse:.4f}    | New_rmse      = {new_rmse:.4f}\")\n",
        "    print(f\"Old_r²        = {old_r2:.4f}      | new_r²        = {new_r2:.4f}\")\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    if new_mse < old_mse:\n",
        "        print(\"🔁 New model is better — overwriting saved model.\")\n",
        "        torch.save(new_model.state_dict(), model_pytorch_path)\n",
        "\n",
        "        with open(model_json_path, \"w\") as f:\n",
        "            json.dump(best_trial.params, f, indent=4)\n",
        "\n",
        "        with open(seed_path, \"w\") as file:\n",
        "            file.write(str(SEED))\n",
        "\n",
        "        model = new_model\n",
        "        model_params = best_trial.params\n",
        "    else:\n",
        "        print(\"✅ Existing model is still better.\")\n",
        "        model = old_model\n",
        "        model_params = best_old_params\n",
        "else:\n",
        "    print(\"Model Score:\")\n",
        "    print(f\"New_mse       = {new_mse:.4f}\")\n",
        "    print(f\"New_mae       = {new_mae:.4f}\")\n",
        "    print(f\"New_rmse      = {new_rmse:.4f}\")\n",
        "    print(f\"new_r²        = {new_r2:.4f}\")\n",
        "    print()\n",
        "    print()\n",
        "    print(\"📥 No existing model — saving new model.\")\n",
        "    os.makedirs(os.path.join(project_path, \"models/word2vec_lstm/\"), exist_ok=True)\n",
        "    torch.save(new_model.state_dict(), model_pytorch_path)\n",
        "    with open(model_json_path, \"w\") as f:\n",
        "        json.dump(best_trial.params, f, indent=4)\n",
        "    with open(seed_path, \"w\") as file:\n",
        "        file.write(str(SEED))\n",
        "    model = new_model\n",
        "    model_params = best_trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0357ccf1",
      "metadata": {
        "id": "0357ccf1"
      },
      "outputs": [],
      "source": [
        "for key, value in model_params.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "background_texts = train_df[\"clean_text\"].sample(50, random_state=42)\n",
        "test_texts = test_df[\"clean_text\"].sample(50, random_state=42)\n",
        "\n",
        "def get_predictions(text_inputs):\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(text_inputs, str):\n",
        "        texts = [text_inputs]\n",
        "    elif isinstance(text_inputs, np.ndarray):\n",
        "        texts = text_inputs.flatten().tolist()\n",
        "    elif isinstance(text_inputs, list):\n",
        "        texts = text_inputs\n",
        "    else:\n",
        "        raise TypeError(f\"Unexpected input type: {type(text_inputs)}\")\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    for text in texts:\n",
        "        tokenized_text = clean_text(\n",
        "            text=text,\n",
        "            tokenize=True,\n",
        "            remove_stop_words=True,\n",
        "            stem_words=True,\n",
        "            remove_url=True,\n",
        "            remove_emojis=\"keep\"\n",
        "        )\n",
        "\n",
        "        vectorized_text = get_vectors(tokens=tokenized_text)\n",
        "\n",
        "        if not vectorized_text:\n",
        "            all_predictions.append(0.0)\n",
        "            continue\n",
        "\n",
        "        padded_text = pad_sequences(\n",
        "            [vectorized_text],\n",
        "            max_len=max_padding_len\n",
        "        )\n",
        "\n",
        "        if isinstance(padded_text, np.ndarray):\n",
        "            padded_text = torch.from_numpy(padded_text)\n",
        "\n",
        "        padded_text = padded_text.float().to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(padded_text)\n",
        "\n",
        "        all_predictions.append(output.squeeze().cpu().numpy().item())\n",
        "\n",
        "    return np.array(all_predictions)"
      ],
      "metadata": {
        "id": "iHEmiHa1Eezf"
      },
      "id": "iHEmiHa1Eezf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "background_data_for_shap = np.array(background_texts.tolist()).reshape(-1, 1)\n",
        "test_data_for_shap = np.array(test_texts.tolist()).reshape(-1, 1)\n",
        "\n",
        "explainer = shap.KernelExplainer(\n",
        "    get_predictions,\n",
        "    background_data_for_shap\n",
        ")\n",
        "\n",
        "shap_values = explainer.shap_values(test_data_for_shap)\n",
        "\n",
        "shap_exp = shap.Explanation(\n",
        "    values=shap_values,\n",
        "    data=test_texts.tolist(),\n",
        "    feature_names=None\n",
        ")\n",
        "\n",
        "shap.plots.bar(shap_exp)"
      ],
      "metadata": {
        "id": "dRrfaa6NEghW"
      },
      "id": "dRrfaa6NEghW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}